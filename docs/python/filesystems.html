


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>File System Interfaces &mdash; Apache Arrow v0.13.0</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="pyarrow.hdfs.connect" href="generated/pyarrow.hdfs.connect.html" />
    <link rel="prev" title="Streaming, Serialization, and IPC" href="ipc.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Apache Arrow
          

          
          </a>

          
            
            
              <div class="version">
                0.13.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Arrow Columnar Format</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../format/README.html">Arrow specification documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format/Guidelines.html">Implementation guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format/Layout.html">Physical memory layout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format/Metadata.html">Metadata: Logical types, schemas, data headers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../format/IPC.html">Interprocess messaging / communication (IPC)</a></li>
</ul>
<p class="caption"><span class="caption-text">Arrow Libraries</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../cpp/index.html">C++ Implementation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python bindings</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="install.html">Installing PyArrow</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory.html">Memory and IO Interfaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.html">Data Types and In-Memory Data Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="ipc.html">Streaming, Serialization, and IPC</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">File System Interfaces</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hadoop-file-system-hdfs">Hadoop File System (HDFS)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hdfs-api">HDFS API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plasma.html">The Plasma In-Memory Object Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy.html">NumPy Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="pandas.html">Pandas Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="timestamps.html">Timestamps</a></li>
<li class="toctree-l2"><a class="reference internal" href="csv.html">Reading CSV files</a></li>
<li class="toctree-l2"><a class="reference internal" href="parquet.html">Reading and Writing the Apache Parquet Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html">CUDA Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="extending.html">Using pyarrow from C++ and Cython Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html">API Reference</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_involved.html">Getting Involved</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarks.html">Benchmarks</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Development and Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../developers/contributing.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developers/cpp.html">C++ Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developers/python.html">Python Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developers/integration.html">Integration Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developers/documentation.html">Building the Documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Apache Arrow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Python bindings</a> &raquo;</li>
        
      <li>File System Interfaces</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/python/filesystems.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="file-system-interfaces">
<h1>File System Interfaces<a class="headerlink" href="#file-system-interfaces" title="Permalink to this headline">¶</a></h1>
<p>In this section, we discuss filesystem-like interfaces in PyArrow.</p>
<div class="section" id="hadoop-file-system-hdfs">
<span id="hdfs"></span><h2>Hadoop File System (HDFS)<a class="headerlink" href="#hadoop-file-system-hdfs" title="Permalink to this headline">¶</a></h2>
<p>PyArrow comes with bindings to a C++-based interface to the Hadoop File
System. You connect like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyarrow</span> <span class="kn">as</span> <span class="nn">pa</span>
<span class="n">fs</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span> <span class="n">kerb_ticket</span><span class="o">=</span><span class="n">ticket_cache_path</span><span class="p">)</span>
<span class="k">with</span> <span class="n">fs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># Do something with f</span>
</pre></div>
</div>
<p>By default, <code class="docutils literal notranslate"><span class="pre">pyarrow.hdfs.HadoopFileSystem</span></code> uses libhdfs, a JNI-based
interface to the Java Hadoop client. This library is loaded <strong>at runtime</strong>
(rather than at link / library load time, since the library may not be in your
LD_LIBRARY_PATH), and relies on some environment variables.</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">HADOOP_HOME</span></code>: the root of your installed Hadoop distribution. Often has
<cite>lib/native/libhdfs.so</cite>.</li>
<li><code class="docutils literal notranslate"><span class="pre">JAVA_HOME</span></code>: the location of your Java SDK installation.</li>
<li><code class="docutils literal notranslate"><span class="pre">ARROW_LIBHDFS_DIR</span></code> (optional): explicit location of <code class="docutils literal notranslate"><span class="pre">libhdfs.so</span></code> if it is
installed somewhere other than <code class="docutils literal notranslate"><span class="pre">$HADOOP_HOME/lib/native</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">CLASSPATH</span></code>: must contain the Hadoop jars. You can set these using:</li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">CLASSPATH</span><span class="o">=</span><span class="sb">`</span><span class="nv">$HADOOP_HOME</span>/bin/hdfs classpath --glob<span class="sb">`</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">CLASSPATH</span></code> is not set, then it will be set automatically if the
<code class="docutils literal notranslate"><span class="pre">hadoop</span></code> executable is in your system path, or if <code class="docutils literal notranslate"><span class="pre">HADOOP_HOME</span></code> is set.</p>
<p>You can also use libhdfs3, a thirdparty C++ library for HDFS from Pivotal Labs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fs</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span> <span class="n">kerb_ticket</span><span class="o">=</span><span class="n">ticket_cache_path</span><span class="p">,</span>
                    <span class="n">driver</span><span class="o">=</span><span class="s1">&#39;libhdfs3&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="hdfs-api">
<h3>HDFS API<a class="headerlink" href="#hdfs-api" title="Permalink to this headline">¶</a></h3>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.hdfs.connect.html#pyarrow.hdfs.connect" title="pyarrow.hdfs.connect"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hdfs.connect</span></code></a>([host,&nbsp;port,&nbsp;user,&nbsp;…])</td>
<td>Connect to an HDFS cluster.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.cat.html#pyarrow.HadoopFileSystem.cat" title="pyarrow.HadoopFileSystem.cat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.cat</span></code></a>(path)</td>
<td>Return contents of file as a bytes object</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.chmod.html#pyarrow.HadoopFileSystem.chmod" title="pyarrow.HadoopFileSystem.chmod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.chmod</span></code></a>(self,&nbsp;path,&nbsp;mode)</td>
<td>Change file permissions</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.chown.html#pyarrow.HadoopFileSystem.chown" title="pyarrow.HadoopFileSystem.chown"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.chown</span></code></a>(self,&nbsp;path[,&nbsp;owner,&nbsp;…])</td>
<td>Change file permissions</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.delete.html#pyarrow.HadoopFileSystem.delete" title="pyarrow.HadoopFileSystem.delete"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.delete</span></code></a>(path[,&nbsp;recursive])</td>
<td>Delete the indicated file or directory</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.df.html#pyarrow.HadoopFileSystem.df" title="pyarrow.HadoopFileSystem.df"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.df</span></code></a>(self)</td>
<td>Return free space on disk, like the UNIX df command</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.disk_usage.html#pyarrow.HadoopFileSystem.disk_usage" title="pyarrow.HadoopFileSystem.disk_usage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.disk_usage</span></code></a>(path)</td>
<td>Compute bytes used by all contents under indicated path in file tree</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.download.html#pyarrow.HadoopFileSystem.download" title="pyarrow.HadoopFileSystem.download"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.download</span></code></a>(self,&nbsp;path,&nbsp;stream)</td>
<td></td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.exists.html#pyarrow.HadoopFileSystem.exists" title="pyarrow.HadoopFileSystem.exists"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.exists</span></code></a>(self,&nbsp;path)</td>
<td>Returns True if the path is known to the cluster, False if it does not (or there is an RPC error)</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.get_capacity.html#pyarrow.HadoopFileSystem.get_capacity" title="pyarrow.HadoopFileSystem.get_capacity"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.get_capacity</span></code></a>(self)</td>
<td>Get reported total capacity of file system</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.get_space_used.html#pyarrow.HadoopFileSystem.get_space_used" title="pyarrow.HadoopFileSystem.get_space_used"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.get_space_used</span></code></a>(self)</td>
<td>Get space used on file system</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.info.html#pyarrow.HadoopFileSystem.info" title="pyarrow.HadoopFileSystem.info"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.info</span></code></a>(self,&nbsp;path)</td>
<td>Return detailed HDFS information for path</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.ls.html#pyarrow.HadoopFileSystem.ls" title="pyarrow.HadoopFileSystem.ls"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.ls</span></code></a>(path[,&nbsp;detail])</td>
<td>Retrieve directory contents and metadata, if requested.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.mkdir.html#pyarrow.HadoopFileSystem.mkdir" title="pyarrow.HadoopFileSystem.mkdir"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.mkdir</span></code></a>(path,&nbsp;**kwargs)</td>
<td>Create directory in HDFS</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.open.html#pyarrow.HadoopFileSystem.open" title="pyarrow.HadoopFileSystem.open"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.open</span></code></a>(self,&nbsp;path[,&nbsp;mode,&nbsp;…])</td>
<td>Open HDFS file for reading or writing</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.rename.html#pyarrow.HadoopFileSystem.rename" title="pyarrow.HadoopFileSystem.rename"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.rename</span></code></a>(path,&nbsp;new_path)</td>
<td>Rename file, like UNIX mv command</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.rm.html#pyarrow.HadoopFileSystem.rm" title="pyarrow.HadoopFileSystem.rm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.rm</span></code></a>(path[,&nbsp;recursive])</td>
<td>Alias for FileSystem.delete</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="generated/pyarrow.HadoopFileSystem.upload.html#pyarrow.HadoopFileSystem.upload" title="pyarrow.HadoopFileSystem.upload"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HadoopFileSystem.upload</span></code></a>(self,&nbsp;path,&nbsp;stream)</td>
<td>Upload file-like object to HDFS path</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="generated/pyarrow.HdfsFile.html#pyarrow.HdfsFile" title="pyarrow.HdfsFile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">HdfsFile</span></code></a></td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/pyarrow.hdfs.connect.html" class="btn btn-neutral float-right" title="pyarrow.hdfs.connect" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="ipc.html" class="btn btn-neutral float-left" title="Streaming, Serialization, and IPC" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016-2018 Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107500873-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-107500873-1');
</script>


</body>
</html>