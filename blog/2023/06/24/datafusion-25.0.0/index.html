<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above meta tags *must* come first in the head; any other head content must come *after* these tags -->
    
    <title>Apache Arrow DataFusion 26.0.0 | Apache Arrow</title>
    

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Apache Arrow DataFusion 26.0.0" />
<meta name="author" content="pmc" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="It has been a whirlwind 6 months of DataFusion development since our last update: the community has grown, many features have been added, performance improved and we are discussing branching out to our own top level Apache Project. Background Apache Arrow DataFusion is an extensible query engine and database toolkit, written in Rust, that uses Apache Arrow as its in-memory format. DataFusion, along with Apache Calcite, Facebook&#39;s Velox and similar technology are part of the next generation &quot;Deconstructed Database&quot; architectures, where new systems are built on a foundation of fast, modular components, rather as a single tightly integrated system. While single tightly integrated systems such as Spark, DuckDB and Pola.rs are great pieces of technology, our community believes that anyone developing new data heavy application, such as those common in machine learning in the next 5 years, will require a high performance, vectorized, query engine to remain relevant. The only practical way to gain access to such technology without investing many millions of dollars to build a new tightly integrated engine, is though open source projects like DataFusion and similar enabling technologies such as Apache Arrow and Rust. DataFusion is targeted primarily at developers creating other data intensive analytics, and offers: High performance, native, parallel streaming execution engine Mature SQL support, featuring subqueries, window functions, grouping sets, and more Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others Native DataFrame API and python bindings Well documented source code and architecture, designed to be customized to suit downstream project needs High quality, easy to use code released every 2 weeks to crates.io Welcoming, open community, governed by the highly regarded and well understood Apache Software Foundation The rest of this post highlights some of the improvements we have made to DataFusion over the last 6 months and a preview of where we are heading. You can see a list of all changes in the detailed CHANGELOG. (Even) Better Performance Various benchmarks show DataFusion to be quite close or even faster to the state of the art in analytic performance (at the moment this seems to be DuckDB). We continually work on improving performance (see #5546 for a list) and would love additional help in this area. DataFusion now reads single large Parquet files significantly faster by parallelizing across multiple cores. Native speeds for reading JSON and CSV files are also up to 2.5x faster thanks to improvements upstream in arrow-rs JSON reader and CSV reader. Also, we have integrated the arrow-rs Row Format into DataFusion resulting in up to 2-3x faster sorting and merging. Improved Documentation and Website Part of growing the DataFusion community is ensuring that DataFusion&#39;s features are understood and that it is easy to contribute and participate. To that end the website has been cleaned up, the architecture guide expanded, the roadmap updated, and several overview talks created: Apr 2023 Query Engine: recording and slides April 2023 Logical Plan and Expressions: recording and slides April 2023 Physical Plan and Execution: recording and slides New Features More Streaming, Less Memory We have made significant progress on the streaming execution roadmap such as unbounded datasources, streaming group by, sophisticated sort and repartitioning improvements in the optimizer, and support for symmetric hash join (read more about that in the great Synnada Blog Post on the topic). Together, these features both 1) make it easier to build streaming systems using DataFusion that can incrementally generate output before (or ever) seeing the end of the input and 2) allow general queries to use less memory and generate their results faster. We have also improved the runtime memory management system so that DataFusion now stays within its declared memory budget generate runtime errors. DML Support (INSERT, DELETE, UPDATE, etc) Part of building high performance data systems includes writing data, and DataFusion supports several features for creating new files: INSERT INTO and SELECT ... INTO support for memory backed and CSV tables New API for writing data into TableProviders We are working on easier to use COPY INTO syntax, better support for writing parquet, JSON, and AVRO, and more -- see our tracking epic for more details. Timestamp and Intervals One mark of the maturity of a SQL engine is how it handles the tricky world of timestamp, date, times and interval arithmetic. DataFusion is feature complete in this area and behaves as you would expect, supporting queries such as SELECT now() + &#39;1 month&#39; FROM my_table; We still have a long tail of date and time improvements, which we are working on as well. Querying Structured Types (List and Structs) Arrow and Parquet support nested data well and DataFusion lets you easily query such Struct and List. For example, you can use DataFusion to read and query the JSON Datasets for Exploratory OLAP - Mendeley Data like this: ---------- -- Explore structured data using SQL ---------- SELECT delete FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL limit 10; +---------------------------------------------------------------------------------------------------------------------------+ | delete | +---------------------------------------------------------------------------------------------------------------------------+ | {status: {id: {$numberLong: 135037425050320896}, id_str: 135037425050320896, user_id: 334902461, user_id_str: 334902461}} | | {status: {id: {$numberLong: 134703982051463168}, id_str: 134703982051463168, user_id: 405383453, user_id_str: 405383453}} | | {status: {id: {$numberLong: 134773741740765184}, id_str: 134773741740765184, user_id: 64823441, user_id_str: 64823441}} | | {status: {id: {$numberLong: 132543659655704576}, id_str: 132543659655704576, user_id: 45917834, user_id_str: 45917834}} | | {status: {id: {$numberLong: 133786431926697984}, id_str: 133786431926697984, user_id: 67229952, user_id_str: 67229952}} | | {status: {id: {$numberLong: 134619093570560002}, id_str: 134619093570560002, user_id: 182430773, user_id_str: 182430773}} | | {status: {id: {$numberLong: 134019857527214080}, id_str: 134019857527214080, user_id: 257396311, user_id_str: 257396311}} | | {status: {id: {$numberLong: 133931546469076993}, id_str: 133931546469076993, user_id: 124539548, user_id_str: 124539548}} | | {status: {id: {$numberLong: 134397743350296576}, id_str: 134397743350296576, user_id: 139836391, user_id_str: 139836391}} | | {status: {id: {$numberLong: 127833661767823360}, id_str: 127833661767823360, user_id: 244442687, user_id_str: 244442687}} | +---------------------------------------------------------------------------------------------------------------------------+ ---------- -- Select some deeply nested fields ---------- SELECT delete[&#39;status&#39;][&#39;id&#39;][&#39;$numberLong&#39;] as delete_id, delete[&#39;status&#39;][&#39;user_id&#39;] as delete_user_id FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL LIMIT 10; +--------------------+----------------+ | delete_id | delete_user_id | +--------------------+----------------+ | 135037425050320896 | 334902461 | | 134703982051463168 | 405383453 | | 134773741740765184 | 64823441 | | 132543659655704576 | 45917834 | | 133786431926697984 | 67229952 | | 134619093570560002 | 182430773 | | 134019857527214080 | 257396311 | | 133931546469076993 | 124539548 | | 134397743350296576 | 139836391 | | 127833661767823360 | 244442687 | +--------------------+----------------+ Subqueries All the Way Down DataFusion can run many different subqueries by rewriting them to joins. It has been able to run the full suite of TPC-H queries for at least the last year, but recently we have implemented significant improvements to this logic, sufficient to run almost all queries in the TPC-DS benchmark as well. Community and Project Growth The six months since our last update saw significant growth in the DataFusion community. Between versions 17.0.0 and 26.0.0, DataFusion merged 711 PRs from 107 distinct contributors, not including all the work that goes into our core dependencies such as arrow, parquet, and object_store, that much of the same community helps support. In addition, we have added 7 new committers and 1 new PMC member to the Apache Arrow project, largely focused on DataFusion, and we learned about some of the cool new systems which are using DataFusion. Given the growth of the community and interest in the project, we also clarified the mission statement and are discussing &quot;graduate&quot;ing DataFusion to a new top level Apache Software Foundation project. $ git shortlog -sn 17.0.0..26.0.0 . | wc -l 107 --&gt; How to Get Involved Kudos to everyone in the community who has contributed ideas, discussions, bug reports, documentation and code. It is exciting to be innovating on the next generation of database architectures together! If you are interested in contributing to DataFusion, we would love to have you join us. You can try out DataFusion on some of your own data and projects and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable for beginners is here. Check out our Communication Doc for more ways to engage with the community." />
<meta property="og:description" content="It has been a whirlwind 6 months of DataFusion development since our last update: the community has grown, many features have been added, performance improved and we are discussing branching out to our own top level Apache Project. Background Apache Arrow DataFusion is an extensible query engine and database toolkit, written in Rust, that uses Apache Arrow as its in-memory format. DataFusion, along with Apache Calcite, Facebook&#39;s Velox and similar technology are part of the next generation &quot;Deconstructed Database&quot; architectures, where new systems are built on a foundation of fast, modular components, rather as a single tightly integrated system. While single tightly integrated systems such as Spark, DuckDB and Pola.rs are great pieces of technology, our community believes that anyone developing new data heavy application, such as those common in machine learning in the next 5 years, will require a high performance, vectorized, query engine to remain relevant. The only practical way to gain access to such technology without investing many millions of dollars to build a new tightly integrated engine, is though open source projects like DataFusion and similar enabling technologies such as Apache Arrow and Rust. DataFusion is targeted primarily at developers creating other data intensive analytics, and offers: High performance, native, parallel streaming execution engine Mature SQL support, featuring subqueries, window functions, grouping sets, and more Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others Native DataFrame API and python bindings Well documented source code and architecture, designed to be customized to suit downstream project needs High quality, easy to use code released every 2 weeks to crates.io Welcoming, open community, governed by the highly regarded and well understood Apache Software Foundation The rest of this post highlights some of the improvements we have made to DataFusion over the last 6 months and a preview of where we are heading. You can see a list of all changes in the detailed CHANGELOG. (Even) Better Performance Various benchmarks show DataFusion to be quite close or even faster to the state of the art in analytic performance (at the moment this seems to be DuckDB). We continually work on improving performance (see #5546 for a list) and would love additional help in this area. DataFusion now reads single large Parquet files significantly faster by parallelizing across multiple cores. Native speeds for reading JSON and CSV files are also up to 2.5x faster thanks to improvements upstream in arrow-rs JSON reader and CSV reader. Also, we have integrated the arrow-rs Row Format into DataFusion resulting in up to 2-3x faster sorting and merging. Improved Documentation and Website Part of growing the DataFusion community is ensuring that DataFusion&#39;s features are understood and that it is easy to contribute and participate. To that end the website has been cleaned up, the architecture guide expanded, the roadmap updated, and several overview talks created: Apr 2023 Query Engine: recording and slides April 2023 Logical Plan and Expressions: recording and slides April 2023 Physical Plan and Execution: recording and slides New Features More Streaming, Less Memory We have made significant progress on the streaming execution roadmap such as unbounded datasources, streaming group by, sophisticated sort and repartitioning improvements in the optimizer, and support for symmetric hash join (read more about that in the great Synnada Blog Post on the topic). Together, these features both 1) make it easier to build streaming systems using DataFusion that can incrementally generate output before (or ever) seeing the end of the input and 2) allow general queries to use less memory and generate their results faster. We have also improved the runtime memory management system so that DataFusion now stays within its declared memory budget generate runtime errors. DML Support (INSERT, DELETE, UPDATE, etc) Part of building high performance data systems includes writing data, and DataFusion supports several features for creating new files: INSERT INTO and SELECT ... INTO support for memory backed and CSV tables New API for writing data into TableProviders We are working on easier to use COPY INTO syntax, better support for writing parquet, JSON, and AVRO, and more -- see our tracking epic for more details. Timestamp and Intervals One mark of the maturity of a SQL engine is how it handles the tricky world of timestamp, date, times and interval arithmetic. DataFusion is feature complete in this area and behaves as you would expect, supporting queries such as SELECT now() + &#39;1 month&#39; FROM my_table; We still have a long tail of date and time improvements, which we are working on as well. Querying Structured Types (List and Structs) Arrow and Parquet support nested data well and DataFusion lets you easily query such Struct and List. For example, you can use DataFusion to read and query the JSON Datasets for Exploratory OLAP - Mendeley Data like this: ---------- -- Explore structured data using SQL ---------- SELECT delete FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL limit 10; +---------------------------------------------------------------------------------------------------------------------------+ | delete | +---------------------------------------------------------------------------------------------------------------------------+ | {status: {id: {$numberLong: 135037425050320896}, id_str: 135037425050320896, user_id: 334902461, user_id_str: 334902461}} | | {status: {id: {$numberLong: 134703982051463168}, id_str: 134703982051463168, user_id: 405383453, user_id_str: 405383453}} | | {status: {id: {$numberLong: 134773741740765184}, id_str: 134773741740765184, user_id: 64823441, user_id_str: 64823441}} | | {status: {id: {$numberLong: 132543659655704576}, id_str: 132543659655704576, user_id: 45917834, user_id_str: 45917834}} | | {status: {id: {$numberLong: 133786431926697984}, id_str: 133786431926697984, user_id: 67229952, user_id_str: 67229952}} | | {status: {id: {$numberLong: 134619093570560002}, id_str: 134619093570560002, user_id: 182430773, user_id_str: 182430773}} | | {status: {id: {$numberLong: 134019857527214080}, id_str: 134019857527214080, user_id: 257396311, user_id_str: 257396311}} | | {status: {id: {$numberLong: 133931546469076993}, id_str: 133931546469076993, user_id: 124539548, user_id_str: 124539548}} | | {status: {id: {$numberLong: 134397743350296576}, id_str: 134397743350296576, user_id: 139836391, user_id_str: 139836391}} | | {status: {id: {$numberLong: 127833661767823360}, id_str: 127833661767823360, user_id: 244442687, user_id_str: 244442687}} | +---------------------------------------------------------------------------------------------------------------------------+ ---------- -- Select some deeply nested fields ---------- SELECT delete[&#39;status&#39;][&#39;id&#39;][&#39;$numberLong&#39;] as delete_id, delete[&#39;status&#39;][&#39;user_id&#39;] as delete_user_id FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL LIMIT 10; +--------------------+----------------+ | delete_id | delete_user_id | +--------------------+----------------+ | 135037425050320896 | 334902461 | | 134703982051463168 | 405383453 | | 134773741740765184 | 64823441 | | 132543659655704576 | 45917834 | | 133786431926697984 | 67229952 | | 134619093570560002 | 182430773 | | 134019857527214080 | 257396311 | | 133931546469076993 | 124539548 | | 134397743350296576 | 139836391 | | 127833661767823360 | 244442687 | +--------------------+----------------+ Subqueries All the Way Down DataFusion can run many different subqueries by rewriting them to joins. It has been able to run the full suite of TPC-H queries for at least the last year, but recently we have implemented significant improvements to this logic, sufficient to run almost all queries in the TPC-DS benchmark as well. Community and Project Growth The six months since our last update saw significant growth in the DataFusion community. Between versions 17.0.0 and 26.0.0, DataFusion merged 711 PRs from 107 distinct contributors, not including all the work that goes into our core dependencies such as arrow, parquet, and object_store, that much of the same community helps support. In addition, we have added 7 new committers and 1 new PMC member to the Apache Arrow project, largely focused on DataFusion, and we learned about some of the cool new systems which are using DataFusion. Given the growth of the community and interest in the project, we also clarified the mission statement and are discussing &quot;graduate&quot;ing DataFusion to a new top level Apache Software Foundation project. $ git shortlog -sn 17.0.0..26.0.0 . | wc -l 107 --&gt; How to Get Involved Kudos to everyone in the community who has contributed ideas, discussions, bug reports, documentation and code. It is exciting to be innovating on the next generation of database architectures together! If you are interested in contributing to DataFusion, we would love to have you join us. You can try out DataFusion on some of your own data and projects and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable for beginners is here. Check out our Communication Doc for more ways to engage with the community." />
<link rel="canonical" href="https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/" />
<meta property="og:url" content="https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/" />
<meta property="og:site_name" content="Apache Arrow" />
<meta property="og:image" content="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-06-24T00:00:00-04:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png" />
<meta property="twitter:title" content="Apache Arrow DataFusion 26.0.0" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"pmc"},"dateModified":"2023-06-24T00:00:00-04:00","datePublished":"2023-06-24T00:00:00-04:00","description":"It has been a whirlwind 6 months of DataFusion development since our last update: the community has grown, many features have been added, performance improved and we are discussing branching out to our own top level Apache Project. Background Apache Arrow DataFusion is an extensible query engine and database toolkit, written in Rust, that uses Apache Arrow as its in-memory format. DataFusion, along with Apache Calcite, Facebook&#39;s Velox and similar technology are part of the next generation &quot;Deconstructed Database&quot; architectures, where new systems are built on a foundation of fast, modular components, rather as a single tightly integrated system. While single tightly integrated systems such as Spark, DuckDB and Pola.rs are great pieces of technology, our community believes that anyone developing new data heavy application, such as those common in machine learning in the next 5 years, will require a high performance, vectorized, query engine to remain relevant. The only practical way to gain access to such technology without investing many millions of dollars to build a new tightly integrated engine, is though open source projects like DataFusion and similar enabling technologies such as Apache Arrow and Rust. DataFusion is targeted primarily at developers creating other data intensive analytics, and offers: High performance, native, parallel streaming execution engine Mature SQL support, featuring subqueries, window functions, grouping sets, and more Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others Native DataFrame API and python bindings Well documented source code and architecture, designed to be customized to suit downstream project needs High quality, easy to use code released every 2 weeks to crates.io Welcoming, open community, governed by the highly regarded and well understood Apache Software Foundation The rest of this post highlights some of the improvements we have made to DataFusion over the last 6 months and a preview of where we are heading. You can see a list of all changes in the detailed CHANGELOG. (Even) Better Performance Various benchmarks show DataFusion to be quite close or even faster to the state of the art in analytic performance (at the moment this seems to be DuckDB). We continually work on improving performance (see #5546 for a list) and would love additional help in this area. DataFusion now reads single large Parquet files significantly faster by parallelizing across multiple cores. Native speeds for reading JSON and CSV files are also up to 2.5x faster thanks to improvements upstream in arrow-rs JSON reader and CSV reader. Also, we have integrated the arrow-rs Row Format into DataFusion resulting in up to 2-3x faster sorting and merging. Improved Documentation and Website Part of growing the DataFusion community is ensuring that DataFusion&#39;s features are understood and that it is easy to contribute and participate. To that end the website has been cleaned up, the architecture guide expanded, the roadmap updated, and several overview talks created: Apr 2023 Query Engine: recording and slides April 2023 Logical Plan and Expressions: recording and slides April 2023 Physical Plan and Execution: recording and slides New Features More Streaming, Less Memory We have made significant progress on the streaming execution roadmap such as unbounded datasources, streaming group by, sophisticated sort and repartitioning improvements in the optimizer, and support for symmetric hash join (read more about that in the great Synnada Blog Post on the topic). Together, these features both 1) make it easier to build streaming systems using DataFusion that can incrementally generate output before (or ever) seeing the end of the input and 2) allow general queries to use less memory and generate their results faster. We have also improved the runtime memory management system so that DataFusion now stays within its declared memory budget generate runtime errors. DML Support (INSERT, DELETE, UPDATE, etc) Part of building high performance data systems includes writing data, and DataFusion supports several features for creating new files: INSERT INTO and SELECT ... INTO support for memory backed and CSV tables New API for writing data into TableProviders We are working on easier to use COPY INTO syntax, better support for writing parquet, JSON, and AVRO, and more -- see our tracking epic for more details. Timestamp and Intervals One mark of the maturity of a SQL engine is how it handles the tricky world of timestamp, date, times and interval arithmetic. DataFusion is feature complete in this area and behaves as you would expect, supporting queries such as SELECT now() + &#39;1 month&#39; FROM my_table; We still have a long tail of date and time improvements, which we are working on as well. Querying Structured Types (List and Structs) Arrow and Parquet support nested data well and DataFusion lets you easily query such Struct and List. For example, you can use DataFusion to read and query the JSON Datasets for Exploratory OLAP - Mendeley Data like this: ---------- -- Explore structured data using SQL ---------- SELECT delete FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL limit 10; +---------------------------------------------------------------------------------------------------------------------------+ | delete | +---------------------------------------------------------------------------------------------------------------------------+ | {status: {id: {$numberLong: 135037425050320896}, id_str: 135037425050320896, user_id: 334902461, user_id_str: 334902461}} | | {status: {id: {$numberLong: 134703982051463168}, id_str: 134703982051463168, user_id: 405383453, user_id_str: 405383453}} | | {status: {id: {$numberLong: 134773741740765184}, id_str: 134773741740765184, user_id: 64823441, user_id_str: 64823441}} | | {status: {id: {$numberLong: 132543659655704576}, id_str: 132543659655704576, user_id: 45917834, user_id_str: 45917834}} | | {status: {id: {$numberLong: 133786431926697984}, id_str: 133786431926697984, user_id: 67229952, user_id_str: 67229952}} | | {status: {id: {$numberLong: 134619093570560002}, id_str: 134619093570560002, user_id: 182430773, user_id_str: 182430773}} | | {status: {id: {$numberLong: 134019857527214080}, id_str: 134019857527214080, user_id: 257396311, user_id_str: 257396311}} | | {status: {id: {$numberLong: 133931546469076993}, id_str: 133931546469076993, user_id: 124539548, user_id_str: 124539548}} | | {status: {id: {$numberLong: 134397743350296576}, id_str: 134397743350296576, user_id: 139836391, user_id_str: 139836391}} | | {status: {id: {$numberLong: 127833661767823360}, id_str: 127833661767823360, user_id: 244442687, user_id_str: 244442687}} | +---------------------------------------------------------------------------------------------------------------------------+ ---------- -- Select some deeply nested fields ---------- SELECT delete[&#39;status&#39;][&#39;id&#39;][&#39;$numberLong&#39;] as delete_id, delete[&#39;status&#39;][&#39;user_id&#39;] as delete_user_id FROM &#39;twitter-sample-head-100000.parquet&#39; WHERE delete IS NOT NULL LIMIT 10; +--------------------+----------------+ | delete_id | delete_user_id | +--------------------+----------------+ | 135037425050320896 | 334902461 | | 134703982051463168 | 405383453 | | 134773741740765184 | 64823441 | | 132543659655704576 | 45917834 | | 133786431926697984 | 67229952 | | 134619093570560002 | 182430773 | | 134019857527214080 | 257396311 | | 133931546469076993 | 124539548 | | 134397743350296576 | 139836391 | | 127833661767823360 | 244442687 | +--------------------+----------------+ Subqueries All the Way Down DataFusion can run many different subqueries by rewriting them to joins. It has been able to run the full suite of TPC-H queries for at least the last year, but recently we have implemented significant improvements to this logic, sufficient to run almost all queries in the TPC-DS benchmark as well. Community and Project Growth The six months since our last update saw significant growth in the DataFusion community. Between versions 17.0.0 and 26.0.0, DataFusion merged 711 PRs from 107 distinct contributors, not including all the work that goes into our core dependencies such as arrow, parquet, and object_store, that much of the same community helps support. In addition, we have added 7 new committers and 1 new PMC member to the Apache Arrow project, largely focused on DataFusion, and we learned about some of the cool new systems which are using DataFusion. Given the growth of the community and interest in the project, we also clarified the mission statement and are discussing &quot;graduate&quot;ing DataFusion to a new top level Apache Software Foundation project. $ git shortlog -sn 17.0.0..26.0.0 . | wc -l 107 --&gt; How to Get Involved Kudos to everyone in the community who has contributed ideas, discussions, bug reports, documentation and code. It is exciting to be innovating on the next generation of database architectures together! If you are interested in contributing to DataFusion, we would love to have you join us. You can try out DataFusion on some of your own data and projects and let us know how it goes or contribute a PR with documentation, tests or code. A list of open issues suitable for beginners is here. Check out our Communication Doc for more ways to engage with the community.","headline":"Apache Arrow DataFusion 26.0.0","image":"https://arrow.apache.org/img/arrow-logo_horizontal_black-txt_white-bg.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://arrow.apache.org/img/logo.png"},"name":"pmc"},"url":"https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/"}</script>
<!-- End Jekyll SEO tag -->


    <!-- favicons -->
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png" id="light1">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png" id="light2">
    <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/img/apple-touch-icon.png" id="light3">
    <link rel="apple-touch-icon" type="image/png" sizes="120x120" href="/img/apple-touch-icon-120x120.png" id="light4">
    <link rel="apple-touch-icon" type="image/png" sizes="76x76" href="/img/apple-touch-icon-76x76.png" id="light5">
    <link rel="apple-touch-icon" type="image/png" sizes="60x60" href="/img/apple-touch-icon-60x60.png" id="light6">
    <!-- dark mode favicons -->
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16-dark.png" id="dark1">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32-dark.png" id="dark2">
    <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/img/apple-touch-icon-dark.png" id="dark3">
    <link rel="apple-touch-icon" type="image/png" sizes="120x120" href="/img/apple-touch-icon-120x120-dark.png" id="dark4">
    <link rel="apple-touch-icon" type="image/png" sizes="76x76" href="/img/apple-touch-icon-76x76-dark.png" id="dark5">
    <link rel="apple-touch-icon" type="image/png" sizes="60x60" href="/img/apple-touch-icon-60x60-dark.png" id="dark6">

    <script>
      // Switch to the dark-mode favicons if prefers-color-scheme: dark
      function onUpdate() {
        light1 = document.querySelector('link#light1');
        light2 = document.querySelector('link#light2');
        light3 = document.querySelector('link#light3');
        light4 = document.querySelector('link#light4');
        light5 = document.querySelector('link#light5');
        light6 = document.querySelector('link#light6');

        dark1 = document.querySelector('link#dark1');
        dark2 = document.querySelector('link#dark2');
        dark3 = document.querySelector('link#dark3');
        dark4 = document.querySelector('link#dark4');
        dark5 = document.querySelector('link#dark5');
        dark6 = document.querySelector('link#dark6');

        if (matcher.matches) {
          light1.remove();
          light2.remove();
          light3.remove();
          light4.remove();
          light5.remove();
          light6.remove();
          document.head.append(dark1);
          document.head.append(dark2);
          document.head.append(dark3);
          document.head.append(dark4);
          document.head.append(dark5);
          document.head.append(dark6);
        } else {
          dark1.remove();
          dark2.remove();
          dark3.remove();
          dark4.remove();
          dark5.remove();
          dark6.remove();
          document.head.append(light1);
          document.head.append(light2);
          document.head.append(light3);
          document.head.append(light4);
          document.head.append(light5);
          document.head.append(light6);
        }
      }
      matcher = window.matchMedia('(prefers-color-scheme: dark)');
      matcher.addListener(onUpdate);
      onUpdate();
    </script>

    <link href="/css/main.css" rel="stylesheet">
    <link href="/css/syntax.css" rel="stylesheet">
    <script src="/javascript/main.js"></script>
    
    <!-- Matomo -->
<script>
  var _paq = window._paq = window._paq || [];
  /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
  /* We explicitly disable cookie tracking to avoid privacy issues */
  _paq.push(['disableCookies']);
  _paq.push(['trackPageView']);
  _paq.push(['enableLinkTracking']);
  (function() {
    var u="https://analytics.apache.org/";
    _paq.push(['setTrackerUrl', u+'matomo.php']);
    _paq.push(['setSiteId', '20']);
    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
  })();
</script>
<!-- End Matomo Code -->

    
    <link type="application/atom+xml" rel="alternate" href="https://arrow.apache.org/feed.xml" title="Apache Arrow" />
  </head>


<body class="wrap">
  <header>
    <nav class="navbar navbar-expand-md navbar-dark bg-dark">
  
  <a class="navbar-brand no-padding" href="/"><img src="/img/arrow-inverse-300px.png" height="40px"></a>
  
   <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#arrow-navbar" aria-controls="arrow-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse justify-content-end" id="arrow-navbar">
      <ul class="nav navbar-nav">
        <li class="nav-item"><a class="nav-link" href="/overview/" role="button" aria-haspopup="true" aria-expanded="false">Overview</a></li>
        <li class="nav-item"><a class="nav-link" href="/faq/" role="button" aria-haspopup="true" aria-expanded="false">FAQ</a></li>
        <li class="nav-item"><a class="nav-link" href="/blog" role="button" aria-haspopup="true" aria-expanded="false">Blog</a></li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownGetArrow" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             Get Arrow
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownGetArrow">
            <a class="dropdown-item" href="/install/">Install</a>
            <a class="dropdown-item" href="/release/">Releases</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownDocumentation" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             Docs
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownDocumentation">
            <a class="dropdown-item" href="/docs">Project Docs</a>
            <a class="dropdown-item" href="/docs/format/Columnar.html">Format</a>
            <hr>
            <a class="dropdown-item" href="/docs/c_glib">C GLib</a>
            <a class="dropdown-item" href="/docs/cpp">C++</a>
            <a class="dropdown-item" href="https://arrow.apache.org/dotnet/">.NET</a>
            <a class="dropdown-item" href="https://godoc.org/github.com/apache/arrow/go/arrow" target="_blank" rel="noopener">Go</a>
            <a class="dropdown-item" href="/java/">Java</a>
            <a class="dropdown-item" href="/js/">JavaScript</a>
            <a class="dropdown-item" href="/julia/">Julia</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/blob/main/matlab/README.md" target="_blank" rel="noopener">MATLAB</a>
            <a class="dropdown-item" href="/docs/python">Python</a>
            <a class="dropdown-item" href="/docs/r">R</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/blob/main/ruby/README.md" target="_blank" rel="noopener">Ruby</a>
            <a class="dropdown-item" href="https://docs.rs/arrow/latest" target="_blank" rel="noopener">Rust</a>
            <a class="dropdown-item" href="/swift">Swift</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownSource" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             Source
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownSource">
            <a class="dropdown-item" href="https://github.com/apache/arrow" target="_blank" rel="noopener">Main Repo</a>
            <hr>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/c_glib" target="_blank" rel="noopener">C GLib</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/cpp" target="_blank" rel="noopener">C++</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-dotnet" target="_blank" rel="noopener">.NET</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-go" target="_blank" rel="noopener">Go</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-java" target="_blank" rel="noopener">Java</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-js" target="_blank" rel="noopener">JavaScript</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-julia" target="_blank" rel="noopener">Julia</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/matlab" target="_blank" rel="noopener">MATLAB</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/python" target="_blank" rel="noopener">Python</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/r" target="_blank" rel="noopener">R</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/tree/main/ruby" target="_blank" rel="noopener">Ruby</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-rs" target="_blank" rel="noopener">Rust</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow-swift" target="_blank" rel="noopener">Swift</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownSubprojects" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             Subprojects
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownSubprojects">
            <a class="dropdown-item" href="/adbc">ADBC</a>
            <a class="dropdown-item" href="/docs/format/Flight.html">Arrow Flight</a>
            <a class="dropdown-item" href="/docs/format/FlightSql.html">Arrow Flight SQL</a>
            <a class="dropdown-item" href="https://datafusion.apache.org" target="_blank" rel="noopener">DataFusion</a>
            <a class="dropdown-item" href="/nanoarrow">nanoarrow</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownCommunity" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             Community
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownCommunity">
            <a class="dropdown-item" href="/community/">Communication</a>
            <a class="dropdown-item" href="/docs/developers/index.html">Contributing</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/issues" target="_blank" rel="noopener">Issue Tracker</a>
            <a class="dropdown-item" href="/committers/">Governance</a>
            <a class="dropdown-item" href="/use_cases/">Use Cases</a>
            <a class="dropdown-item" href="/powered_by/">Powered By</a>
            <a class="dropdown-item" href="/visual_identity/">Visual Identity</a>
            <a class="dropdown-item" href="/security/">Security</a>
            <a class="dropdown-item" href="https://www.apache.org/foundation/policies/conduct.html" target="_blank" rel="noopener">Code of Conduct</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownASF" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
             ASF Links
          </a>
          <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownASF">
            <a class="dropdown-item" href="https://www.apache.org/" target="_blank" rel="noopener">ASF Website</a>
            <a class="dropdown-item" href="https://www.apache.org/licenses/" target="_blank" rel="noopener">License</a>
            <a class="dropdown-item" href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener">Donate</a>
            <a class="dropdown-item" href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener">Thanks</a>
            <a class="dropdown-item" href="https://www.apache.org/security/" target="_blank" rel="noopener">Security</a>
          </div>
        </li>
      </ul>
    </div>
<!-- /.navbar-collapse -->
  </nav>

  </header>

  <div class="container p-4 pt-5">
    <div class="col-md-8 mx-auto">
      <main role="main" class="pb-5">
        
<h1>
  Apache Arrow DataFusion 26.0.0
</h1>
<hr class="mt-4 mb-3">



<p class="mb-4 pb-1">
  <span class="badge badge-secondary">Published</span>
  <span class="published mr-3">
    24 Jun 2023
  </span>
  <br>
  <span class="badge badge-secondary">By</span>
  
    <a class="mr-3" href="https://arrow.apache.org">The Apache Arrow PMC (pmc) </a>
  

  
</p>


        <!--

-->
<p>It has been a whirlwind 6 months of DataFusion development since <a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0">our
last update</a>: the community has grown, many features have been added,
performance improved and we are <a href="https://github.com/apache/arrow-datafusion/discussions/6475" target="_blank" rel="noopener">discussing</a> branching out to our own
top level Apache Project.</p>
<h2>Background</h2>
<p><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> is an extensible query engine and database
toolkit, written in <a href="https://www.rust-lang.org/" target="_blank" rel="noopener">Rust</a>, that uses <a href="https://arrow.apache.org">Apache Arrow</a> as its in-memory
format.</p>
<p>DataFusion, along with <a href="https://calcite.apache.org" target="_blank" rel="noopener">Apache Calcite</a>, Facebook's <a href="https://github.com/facebookincubator/velox" target="_blank" rel="noopener">Velox</a> and
similar technology are part of the next generation "<a href="https://www.usenix.org/publications/login/winter2018/khurana" target="_blank" rel="noopener">Deconstructed
Database</a>" architectures, where new systems are built on a foundation
of fast, modular components, rather as a single tightly integrated
system.</p>
<p>While single tightly integrated systems such as <a href="https://spark.apache.org/" target="_blank" rel="noopener">Spark</a>, <a href="https://duckdb.org" target="_blank" rel="noopener">DuckDB</a> and
<a href="https://www.pola.rs/" target="_blank" rel="noopener">Pola.rs</a> are great pieces of technology, our community believes that
anyone developing new data heavy application, such as those common in
machine learning in the next 5 years, will <strong>require</strong> a high
performance, vectorized, query engine to remain relevant. The only
practical way to gain access to such technology without investing many
millions of dollars to build a new tightly integrated engine, is
though open source projects like DataFusion and similar enabling
technologies such as <a href="https://arrow.apache.org">Apache Arrow</a> and <a href="https://www.rust-lang.org/" target="_blank" rel="noopener">Rust</a>.</p>
<p>DataFusion is targeted primarily at developers creating other data
intensive analytics, and offers:</p>
<ul>
<li>High performance, native, parallel streaming execution engine</li>
<li>Mature <a href="https://arrow.apache.org/datafusion/user-guide/sql/index.html">SQL support</a>, featuring  subqueries, window functions, grouping sets, and more</li>
<li>Built in support for Parquet, Avro, CSV, JSON and Arrow formats and easy extension for others</li>
<li>Native DataFrame API and <a href="https://arrow.apache.org/datafusion-python/">python bindings</a>
</li>
<li>
<a href="https://docs.rs/datafusion/latest/datafusion/index.html" target="_blank" rel="noopener">Well documented</a> source code and architecture, designed to be customized to suit downstream project needs</li>
<li>High quality, easy to use code <a href="https://crates.io/crates/datafusion/versions" target="_blank" rel="noopener">released every 2 weeks to crates.io</a>
</li>
<li>Welcoming, open community, governed by the highly regarded and well understood <a href="https://www.apache.org/" target="_blank" rel="noopener">Apache Software Foundation</a>
</li>
</ul>
<p>The rest of this post highlights some of the improvements we have made
to DataFusion over the last 6 months and a preview of where we are
heading. You can see a list of all changes in the detailed
<a href="https://github.com/apache/arrow-datafusion/blob/main/datafusion/CHANGELOG.md" target="_blank" rel="noopener">CHANGELOG</a>.</p>
<h2>(Even) Better Performance</h2>
<p><a href="https://voltrondata.com/resources/speeds-and-feeds-hardware-and-software-matter" target="_blank" rel="noopener">Various</a> benchmarks show DataFusion to be quite close or <a href="https://github.com/tustvold/access-log-bench" target="_blank" rel="noopener">even
faster</a> to the state of the art in analytic performance (at the moment
this seems to be DuckDB). We continually work on improving performance
(see <a href="https://github.com/apache/arrow-datafusion/issues/5546" target="_blank" rel="noopener">#5546</a> for a list) and would love additional help in this area.</p>
<p>DataFusion now reads single large Parquet files significantly faster by
<a href="https://github.com/apache/arrow-datafusion/pull/5057" target="_blank" rel="noopener">parallelizing across multiple cores</a>. Native speeds for reading JSON
and CSV files are also up to 2.5x faster thanks to improvements
upstream in arrow-rs <a href="https://github.com/apache/arrow-rs/pull/3479#issuecomment-1384353159" target="_blank" rel="noopener">JSON reader</a> and <a href="https://github.com/apache/arrow-rs/pull/3365" target="_blank" rel="noopener">CSV reader</a>.</p>
<p>Also, we have integrated the <a href="https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-1/">arrow-rs Row Format</a> into DataFusion resulting in up to <a href="https://github.com/apache/arrow-datafusion/pull/6163" target="_blank" rel="noopener">2-3x faster sorting and merging</a>.</p>
<h2>Improved Documentation and Website</h2>
<p>Part of growing the DataFusion community is ensuring that DataFusion's
features are understood and that it is easy to contribute and
participate. To that end the <a href="https://arrow.apache.org/datafusion/">website</a> has been cleaned up, <a href="https://docs.rs/datafusion/latest/datafusion/index.html#architecture" target="_blank" rel="noopener">the
architecture guide</a> expanded, the <a href="https://arrow.apache.org/datafusion/contributor-guide/roadmap.html">roadmap</a> updated, and several
overview talks created:</p>
<ul>
<li>Apr 2023 <em>Query Engine</em>: <a href="https://youtu.be/NVKujPxwSBA" target="_blank" rel="noopener">recording</a> and <a href="https://docs.google.com/presentation/d/1D3GDVas-8y0sA4c8EOgdCvEjVND4s2E7I6zfs67Y4j8/edit#slide=id.p" target="_blank" rel="noopener">slides</a>
</li>
<li>April 2023 <em>Logical Plan and Expressions</em>: <a href="https://youtu.be/EzZTLiSJnhY" target="_blank" rel="noopener">recording</a> and <a href="https://docs.google.com/presentation/d/1ypylM3-w60kVDW7Q6S99AHzvlBgciTdjsAfqNP85K30" target="_blank" rel="noopener">slides</a>
</li>
<li>April 2023 <em>Physical Plan and Execution</em>: <a href="https://youtu.be/2jkWU3_w6z0" target="_blank" rel="noopener">recording</a> and <a href="https://docs.google.com/presentation/d/1cA2WQJ2qg6tx6y4Wf8FH2WVSm9JQ5UgmBWATHdik0hg" target="_blank" rel="noopener">slides</a>
</li>
</ul>
<h2>New Features</h2>
<h3>More Streaming, Less Memory</h3>
<p>We have made significant progress on the <a href="https://github.com/apache/arrow-datafusion/issues/4285" target="_blank" rel="noopener">streaming execution roadmap</a>
such as <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.ExecutionPlan.html#method.unbounded_output" target="_blank" rel="noopener">unbounded datasources</a>, <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/aggregates/enum.GroupByOrderMode.html" target="_blank" rel="noopener">streaming group by</a>, sophisticated
<a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/global_sort_selection/index.html" target="_blank" rel="noopener">sort</a> and <a href="https://docs.rs/datafusion/latest/datafusion/physical_optimizer/repartition/index.html" target="_blank" rel="noopener">repartitioning</a> improvements in the optimizer, and support
for <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/joins/struct.SymmetricHashJoinExec.html" target="_blank" rel="noopener">symmetric hash join</a> (read more about that in the great <a href="https://www.synnada.ai/blog/general-purpose-stream-joins-via-pruning-symmetric-hash-joins" target="_blank" rel="noopener">Synnada
Blog Post</a> on the topic). Together, these features both 1) make it
easier to build streaming systems using DataFusion that can
incrementally generate output before (or ever) seeing the end of the
input and 2) allow general queries to use less memory and generate their
results faster.</p>
<p>We have also improved the runtime <a href="https://docs.rs/datafusion/latest/datafusion/execution/memory_pool/index.html" target="_blank" rel="noopener">memory management</a> system so that
DataFusion now stays within its declared memory budget <a href="https://github.com/apache/arrow-datafusion/issues/3941" target="_blank" rel="noopener">generate
runtime errors</a>.</p>
<h3>DML Support (<code>INSERT</code>, <code>DELETE</code>, <code>UPDATE</code>, etc)</h3>
<p>Part of building high performance data systems includes writing data,
and DataFusion supports several features for creating new files:</p>
<ul>
<li>
<code>INSERT INTO</code> and <code>SELECT ... INTO </code> support for memory backed and CSV tables</li>
<li>New <a href="https://docs.rs/datafusion/latest/datafusion/physical_plan/insert/trait.DataSink.html" target="_blank" rel="noopener">API for writing data into TableProviders</a>
</li>
</ul>
<p>We are working on easier to use <a href="https://github.com/apache/arrow-datafusion/issues/5654" target="_blank" rel="noopener">COPY INTO</a> syntax, better support
for writing parquet, JSON, and AVRO, and more -- see our <a href="https://github.com/apache/arrow-datafusion/issues/6569" target="_blank" rel="noopener">tracking epic</a>
for more details.</p>
<h3>Timestamp and Intervals</h3>
<p>One mark of the maturity of a SQL engine is how it handles the tricky
world of timestamp, date, times and interval arithmetic. DataFusion is
feature complete in this area and behaves as you would expect,
supporting queries such as</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code data-lang="sql"><span class="k">SELECT</span> <span class="n">now</span><span class="p">()</span> <span class="o">+</span> <span class="s1">'1 month'</span> <span class="k">FROM</span> <span class="n">my_table</span><span class="p">;</span>
</code></pre></div></div>
<p>We still have a long tail of <a href="https://github.com/apache/arrow-datafusion/issues/3148" target="_blank" rel="noopener">date and time improvements</a>, which we are working on as well.</p>
<h3>Querying Structured Types (<code>List</code> and <code>Struct</code>s)</h3>
<p>Arrow and Parquet <a href="https://arrow.apache.org/blog/2022/10/08/arrow-parquet-encoding-part-2/">support nested data</a> well and DataFusion lets you
easily query such <code>Struct</code> and <code>List</code>. For example, you can use
DataFusion to read and query the <a href="https://data.mendeley.com/datasets/ct8f9skv97" target="_blank" rel="noopener">JSON Datasets for Exploratory OLAP -
Mendeley Data</a> like this:</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code data-lang="sql"><span class="c1">----------</span>
<span class="c1">-- Explore structured data using SQL</span>
<span class="c1">----------</span>
<span class="k">SELECT</span> <span class="k">delete</span> <span class="k">FROM</span> <span class="s1">'twitter-sample-head-100000.parquet'</span> <span class="k">WHERE</span> <span class="k">delete</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">limit</span> <span class="mi">10</span><span class="p">;</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="k">delete</span>                                                                                                                    <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">135037425050320896</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">135037425050320896</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">334902461</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">334902461</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134703982051463168</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134703982051463168</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">405383453</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">405383453</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134773741740765184</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134773741740765184</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">64823441</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">64823441</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">132543659655704576</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">132543659655704576</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">45917834</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">45917834</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">133786431926697984</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">133786431926697984</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">67229952</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">67229952</span><span class="p">}}</span>   <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134619093570560002</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134619093570560002</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">182430773</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">182430773</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134019857527214080</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134019857527214080</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">257396311</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">257396311</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">133931546469076993</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">133931546469076993</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">124539548</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">124539548</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">134397743350296576</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">134397743350296576</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">139836391</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">139836391</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">{</span><span class="n">status</span><span class="p">:</span> <span class="p">{</span><span class="n">id</span><span class="p">:</span> <span class="p">{</span><span class="err">$</span><span class="n">numberLong</span><span class="p">:</span> <span class="mi">127833661767823360</span><span class="p">},</span> <span class="n">id_str</span><span class="p">:</span> <span class="mi">127833661767823360</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="mi">244442687</span><span class="p">,</span> <span class="n">user_id_str</span><span class="p">:</span> <span class="mi">244442687</span><span class="p">}}</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">---------------------------------------------------------------------------------------------------------------------------+</span>

<span class="c1">----------</span>
<span class="c1">-- Select some deeply nested fields</span>
<span class="c1">----------</span>
<span class="k">SELECT</span>
  <span class="k">delete</span><span class="p">[</span><span class="s1">'status'</span><span class="p">][</span><span class="s1">'id'</span><span class="p">][</span><span class="s1">'$numberLong'</span><span class="p">]</span> <span class="k">as</span> <span class="n">delete_id</span><span class="p">,</span>
  <span class="k">delete</span><span class="p">[</span><span class="s1">'status'</span><span class="p">][</span><span class="s1">'user_id'</span><span class="p">]</span> <span class="k">as</span> <span class="n">delete_user_id</span>
<span class="k">FROM</span> <span class="s1">'twitter-sample-head-100000.parquet'</span> <span class="k">WHERE</span> <span class="k">delete</span> <span class="k">IS</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">LIMIT</span> <span class="mi">10</span><span class="p">;</span>

<span class="o">+</span><span class="c1">--------------------+----------------+</span>
<span class="o">|</span> <span class="n">delete_id</span>          <span class="o">|</span> <span class="n">delete_user_id</span> <span class="o">|</span>
<span class="o">+</span><span class="c1">--------------------+----------------+</span>
<span class="o">|</span> <span class="mi">135037425050320896</span> <span class="o">|</span> <span class="mi">334902461</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134703982051463168</span> <span class="o">|</span> <span class="mi">405383453</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134773741740765184</span> <span class="o">|</span> <span class="mi">64823441</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">132543659655704576</span> <span class="o">|</span> <span class="mi">45917834</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">133786431926697984</span> <span class="o">|</span> <span class="mi">67229952</span>       <span class="o">|</span>
<span class="o">|</span> <span class="mi">134619093570560002</span> <span class="o">|</span> <span class="mi">182430773</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134019857527214080</span> <span class="o">|</span> <span class="mi">257396311</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">133931546469076993</span> <span class="o">|</span> <span class="mi">124539548</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">134397743350296576</span> <span class="o">|</span> <span class="mi">139836391</span>      <span class="o">|</span>
<span class="o">|</span> <span class="mi">127833661767823360</span> <span class="o">|</span> <span class="mi">244442687</span>      <span class="o">|</span>
<span class="o">+</span><span class="c1">--------------------+----------------+</span>
</code></pre></div></div>
<h3>Subqueries All the Way Down</h3>
<p>DataFusion can run many different subqueries by rewriting them to
joins. It has been able to run the full suite of TPC-H queries for at
least the last year, but recently we have implemented significant
improvements to this logic, sufficient to run almost all queries in
the TPC-DS benchmark as well.</p>
<h2>Community and Project Growth</h2>
<p>The six months since <a href="https://arrow.apache.org/blog/2023/01/19/datafusion-16.0.0">our last update</a> saw significant growth in
the DataFusion community. Between versions <code>17.0.0</code> and <code>26.0.0</code>,
DataFusion merged 711 PRs from 107 distinct contributors, not
including all the work that goes into our core dependencies such as
<a href="https://crates.io/crates/arrow" target="_blank" rel="noopener">arrow</a>,
<a href="https://crates.io/crates/parquet" target="_blank" rel="noopener">parquet</a>, and
<a href="https://crates.io/crates/object_store" target="_blank" rel="noopener">object_store</a>, that much of
the same community helps support.</p>
<p>In addition, we have added 7 new committers and 1 new PMC member to
the Apache Arrow project, largely focused on DataFusion, and we
learned about some of the cool <a href="https://arrow.apache.org/datafusion/user-guide/introduction.html#known-users">new systems</a> which are using
DataFusion. Given the growth of the community and interest in the
project, we also clarified the <a href="https://github.com/apache/arrow-datafusion/discussions/6441" target="_blank" rel="noopener">mission statement</a> and are
<a href="https://github.com/apache/arrow-datafusion/discussions/6475" target="_blank" rel="noopener">discussing</a> "graduate"ing DataFusion to a new top level
Apache Software Foundation project.</p>
<!--
$ git log --pretty=oneline 17.0.0..26.0.0 . | wc -l
     711

$ git shortlog -sn 17.0.0..26.0.0 . | wc -l
      107
-->
<h1>How to Get Involved</h1>
<p>Kudos to everyone in the community who has contributed ideas,
discussions, bug reports, documentation and code. It is exciting to be
innovating on the next generation of database architectures together!</p>
<p>If you are interested in contributing to DataFusion, we would love to
have you join us. You can try out DataFusion on some of your own
data and projects and let us know how it goes or contribute a PR with
documentation, tests or code. A list of open issues suitable for
beginners is <a href="https://github.com/apache/arrow-datafusion/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22" target="_blank" rel="noopener">here</a>.</p>
<p>Check out our <a href="https://arrow.apache.org/datafusion/contributor-guide/communication.html">Communication Doc</a> for more ways to engage with the
community.</p>

      </main>
    </div>

    <hr>
<footer class="footer">
  <div class="row">
    <div class="col-md-9">
      <p>Apache Arrow, Arrow, Apache, the Apache logo, and the Apache Arrow project logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
      <p> 2016-2025 The Apache Software Foundation</p>
    </div>
    <div class="col-md-3">
      <a class="d-sm-none d-md-inline pr-2" href="https://www.apache.org/events/current-event.html" target="_blank" rel="noopener">
        <img src="https://www.apache.org/events/current-event-234x60.png">
      </a>
    </div>
  </div>
</footer>

  </div>
</body>
</html>
