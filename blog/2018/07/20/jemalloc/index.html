<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above meta tags *must* come first in the head; any other head content must come *after* these tags -->
    
    <title>Faster, scalable memory allocations in Apache Arrow with jemalloc | Apache Arrow</title>
    

    <!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Faster, scalable memory allocations in Apache Arrow with jemalloc" />
<meta name="author" content="uwe" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="With the release of the 0.9 version of Apache Arrow, we have switched our default allocator for array buffers from the system allocator to jemalloc on OSX and Linux. This applies to the C++/GLib/Python implementations of Arrow. In most cases changing the default allocator is normally done to avoid problems that occur with many small, frequent (de)allocations. In contrast, in Arrow we normally deal with large in-memory datasets. While jemalloc provides good strategies for avoiding RAM fragmentation for allocations that are lower than a memory page (4kb), it also provides functionality that improves performance on allocations that span several memory pages. Outside of Apache Arrow, jemalloc powers the infrastructure of Facebook (this is also where most of its development happens). It is also used as the default allocator in Rust as well as it helps Redis reduce the memory fragmentation on Linux (“Allocator”). One allocation specialty that we require in Arrow is that memory should be 64byte aligned. This is so that we can get the most performance out of SIMD instruction sets like AVX. While the most modern SIMD instructions also work on unaligned memory, their performance is much better on aligned memory. To get the best performance for our analytical applications, we want all memory to be allocated such that SIMD performance is maximized. For aligned allocations, the POSIX APIs only provide the aligned_alloc(void** ptr, size_t alignment, size_t size) function to allocate aligned memory. There is also posix_memalign(void **ptr, size_t alignment, size_t size) to modify an allocation to the preferred alignment. But neither of them cater for expansions of the allocation. While the realloc function can often expand allocations without moving them physically, it does not ensure that in the case the allocation is moved that the alignment is kept. In the case when Arrow was built without jemalloc being enabled, this resulted in copying the data on each new expansion of an allocation. To reduce the number of memory copies, we use jemalloc’s *allocx()-APIs to create, modify and free aligned allocations. One of the typical tasks where this gives us a major speedup is on the incremental construction of an Arrow table that consists of several columns. We often don’t know the size of the table in advance and need to expand our allocations as the data is loaded. To incrementally build a vector using memory expansion of a factor of 2, we would use the following C-code with the standard POSIX APIs: size_t size = 128 * 1024; void* ptr = aligned_alloc(64, size); for (int i = 0; i &lt; 10; i++) { size_t new_size = size * 2; void* ptr2 = aligned_alloc(64, new_size); memcpy(ptr2, ptr, size); free(ptr); ptr = ptr2; size = new_size; } free(ptr); With jemalloc’s special APIs, we are able to omit the explicit call to memcpy. In the case where a memory expansion cannot be done in-place, it is still called by the allocator but not needed on all occasions. This simplifies our user code to: size_t size = 128 * 1024; void* ptr = mallocx(size, MALLOCX_ALIGN(64)); for (int i = 0; i &lt; 10; i++) { size *= 2; ptr = rallocx(ptr, size, MALLOCX_ALIGN(64)); } dallocx(ptr, MALLOCX_ALIGN(64)); To see the real world benefits of using jemalloc, we look at the benchmarks in Arrow C++. There we have modeled a typical use case of incrementally building up an array of primitive values. For the build-up of the array, we don’t know the number of elements in the final array so we need to continuously expand the memory region in which the data is stored. The code for this benchmark is part of the builder-benchmark in the Arrow C++ sources as BuildPrimitiveArrayNoNulls. Runtimes without jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 636726 us 804.114MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 621345 us 824.019MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 627693 us 815.774MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 8034 us 10.3829MB/s Runtimes with jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 630881 us 811.563MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 351039 us 1.42434GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 444937 us 1.21125GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 161035 us 371.335MB/s The benchmark was run three times for each configuration to see the performance differences. The first run in each configuration yielded the same performance but in all subsequent runs, the version using jemalloc was about twice as fast. In these cases, the memory region that was used for constructing the array could be expanded in place without moving the data around. This was possible as there were memory pages assigned to the process that were unused but not reclaimed by the operating system. Without jemalloc, we cannot make use of them simply by the fact that the default allocator has no API that provides aligned reallocation." />
<meta property="og:description" content="With the release of the 0.9 version of Apache Arrow, we have switched our default allocator for array buffers from the system allocator to jemalloc on OSX and Linux. This applies to the C++/GLib/Python implementations of Arrow. In most cases changing the default allocator is normally done to avoid problems that occur with many small, frequent (de)allocations. In contrast, in Arrow we normally deal with large in-memory datasets. While jemalloc provides good strategies for avoiding RAM fragmentation for allocations that are lower than a memory page (4kb), it also provides functionality that improves performance on allocations that span several memory pages. Outside of Apache Arrow, jemalloc powers the infrastructure of Facebook (this is also where most of its development happens). It is also used as the default allocator in Rust as well as it helps Redis reduce the memory fragmentation on Linux (“Allocator”). One allocation specialty that we require in Arrow is that memory should be 64byte aligned. This is so that we can get the most performance out of SIMD instruction sets like AVX. While the most modern SIMD instructions also work on unaligned memory, their performance is much better on aligned memory. To get the best performance for our analytical applications, we want all memory to be allocated such that SIMD performance is maximized. For aligned allocations, the POSIX APIs only provide the aligned_alloc(void** ptr, size_t alignment, size_t size) function to allocate aligned memory. There is also posix_memalign(void **ptr, size_t alignment, size_t size) to modify an allocation to the preferred alignment. But neither of them cater for expansions of the allocation. While the realloc function can often expand allocations without moving them physically, it does not ensure that in the case the allocation is moved that the alignment is kept. In the case when Arrow was built without jemalloc being enabled, this resulted in copying the data on each new expansion of an allocation. To reduce the number of memory copies, we use jemalloc’s *allocx()-APIs to create, modify and free aligned allocations. One of the typical tasks where this gives us a major speedup is on the incremental construction of an Arrow table that consists of several columns. We often don’t know the size of the table in advance and need to expand our allocations as the data is loaded. To incrementally build a vector using memory expansion of a factor of 2, we would use the following C-code with the standard POSIX APIs: size_t size = 128 * 1024; void* ptr = aligned_alloc(64, size); for (int i = 0; i &lt; 10; i++) { size_t new_size = size * 2; void* ptr2 = aligned_alloc(64, new_size); memcpy(ptr2, ptr, size); free(ptr); ptr = ptr2; size = new_size; } free(ptr); With jemalloc’s special APIs, we are able to omit the explicit call to memcpy. In the case where a memory expansion cannot be done in-place, it is still called by the allocator but not needed on all occasions. This simplifies our user code to: size_t size = 128 * 1024; void* ptr = mallocx(size, MALLOCX_ALIGN(64)); for (int i = 0; i &lt; 10; i++) { size *= 2; ptr = rallocx(ptr, size, MALLOCX_ALIGN(64)); } dallocx(ptr, MALLOCX_ALIGN(64)); To see the real world benefits of using jemalloc, we look at the benchmarks in Arrow C++. There we have modeled a typical use case of incrementally building up an array of primitive values. For the build-up of the array, we don’t know the number of elements in the final array so we need to continuously expand the memory region in which the data is stored. The code for this benchmark is part of the builder-benchmark in the Arrow C++ sources as BuildPrimitiveArrayNoNulls. Runtimes without jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 636726 us 804.114MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 621345 us 824.019MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 627693 us 815.774MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 8034 us 10.3829MB/s Runtimes with jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 630881 us 811.563MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 351039 us 1.42434GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 444937 us 1.21125GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 161035 us 371.335MB/s The benchmark was run three times for each configuration to see the performance differences. The first run in each configuration yielded the same performance but in all subsequent runs, the version using jemalloc was about twice as fast. In these cases, the memory region that was used for constructing the array could be expanded in place without moving the data around. This was possible as there were memory pages assigned to the process that were unused but not reclaimed by the operating system. Without jemalloc, we cannot make use of them simply by the fact that the default allocator has no API that provides aligned reallocation." />
<link rel="canonical" href="https://arrow.apache.org/blog/2018/07/20/jemalloc/" />
<meta property="og:url" content="https://arrow.apache.org/blog/2018/07/20/jemalloc/" />
<meta property="og:site_name" content="Apache Arrow" />
<meta property="og:image" content="https://arrow.apache.org/img/arrow.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-07-20T07:00:00-04:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://arrow.apache.org/img/arrow.png" />
<meta property="twitter:title" content="Faster, scalable memory allocations in Apache Arrow with jemalloc" />
<meta name="twitter:site" content="@ApacheArrow" />
<meta name="twitter:creator" content="@uwe" />
<script type="application/ld+json">
{"image":"https://arrow.apache.org/img/arrow.png","description":"With the release of the 0.9 version of Apache Arrow, we have switched our default allocator for array buffers from the system allocator to jemalloc on OSX and Linux. This applies to the C++/GLib/Python implementations of Arrow. In most cases changing the default allocator is normally done to avoid problems that occur with many small, frequent (de)allocations. In contrast, in Arrow we normally deal with large in-memory datasets. While jemalloc provides good strategies for avoiding RAM fragmentation for allocations that are lower than a memory page (4kb), it also provides functionality that improves performance on allocations that span several memory pages. Outside of Apache Arrow, jemalloc powers the infrastructure of Facebook (this is also where most of its development happens). It is also used as the default allocator in Rust as well as it helps Redis reduce the memory fragmentation on Linux (“Allocator”). One allocation specialty that we require in Arrow is that memory should be 64byte aligned. This is so that we can get the most performance out of SIMD instruction sets like AVX. While the most modern SIMD instructions also work on unaligned memory, their performance is much better on aligned memory. To get the best performance for our analytical applications, we want all memory to be allocated such that SIMD performance is maximized. For aligned allocations, the POSIX APIs only provide the aligned_alloc(void** ptr, size_t alignment, size_t size) function to allocate aligned memory. There is also posix_memalign(void **ptr, size_t alignment, size_t size) to modify an allocation to the preferred alignment. But neither of them cater for expansions of the allocation. While the realloc function can often expand allocations without moving them physically, it does not ensure that in the case the allocation is moved that the alignment is kept. In the case when Arrow was built without jemalloc being enabled, this resulted in copying the data on each new expansion of an allocation. To reduce the number of memory copies, we use jemalloc’s *allocx()-APIs to create, modify and free aligned allocations. One of the typical tasks where this gives us a major speedup is on the incremental construction of an Arrow table that consists of several columns. We often don’t know the size of the table in advance and need to expand our allocations as the data is loaded. To incrementally build a vector using memory expansion of a factor of 2, we would use the following C-code with the standard POSIX APIs: size_t size = 128 * 1024; void* ptr = aligned_alloc(64, size); for (int i = 0; i &lt; 10; i++) { size_t new_size = size * 2; void* ptr2 = aligned_alloc(64, new_size); memcpy(ptr2, ptr, size); free(ptr); ptr = ptr2; size = new_size; } free(ptr); With jemalloc’s special APIs, we are able to omit the explicit call to memcpy. In the case where a memory expansion cannot be done in-place, it is still called by the allocator but not needed on all occasions. This simplifies our user code to: size_t size = 128 * 1024; void* ptr = mallocx(size, MALLOCX_ALIGN(64)); for (int i = 0; i &lt; 10; i++) { size *= 2; ptr = rallocx(ptr, size, MALLOCX_ALIGN(64)); } dallocx(ptr, MALLOCX_ALIGN(64)); To see the real world benefits of using jemalloc, we look at the benchmarks in Arrow C++. There we have modeled a typical use case of incrementally building up an array of primitive values. For the build-up of the array, we don’t know the number of elements in the final array so we need to continuously expand the memory region in which the data is stored. The code for this benchmark is part of the builder-benchmark in the Arrow C++ sources as BuildPrimitiveArrayNoNulls. Runtimes without jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 636726 us 804.114MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 621345 us 824.019MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 627693 us 815.774MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 625008 us 819.19MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 8034 us 10.3829MB/s Runtimes with jemalloc: BM_BuildPrimitiveArrayNoNulls/repeats:3 630881 us 811.563MB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3 351039 us 1.42434GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_mean 444937 us 1.21125GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_median 352891 us 1.41687GB/s BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev 161035 us 371.335MB/s The benchmark was run three times for each configuration to see the performance differences. The first run in each configuration yielded the same performance but in all subsequent runs, the version using jemalloc was about twice as fast. In these cases, the memory region that was used for constructing the array could be expanded in place without moving the data around. This was possible as there were memory pages assigned to the process that were unused but not reclaimed by the operating system. Without jemalloc, we cannot make use of them simply by the fact that the default allocator has no API that provides aligned reallocation.","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://arrow.apache.org/img/logo.png"},"name":"uwe"},"headline":"Faster, scalable memory allocations in Apache Arrow with jemalloc","dateModified":"2018-07-20T07:00:00-04:00","datePublished":"2018-07-20T07:00:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://arrow.apache.org/blog/2018/07/20/jemalloc/"},"author":{"@type":"Person","name":"uwe"},"url":"https://arrow.apache.org/blog/2018/07/20/jemalloc/","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <!-- favicons -->
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png" id="light1">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png" id="light2">
    <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/img/apple-touch-icon.png" id="light3">
    <link rel="apple-touch-icon" type="image/png" sizes="120x120" href="/img/apple-touch-icon-120x120.png" id="light4">
    <link rel="apple-touch-icon" type="image/png" sizes="76x76" href="/img/apple-touch-icon-76x76.png" id="light5">
    <link rel="apple-touch-icon" type="image/png" sizes="60x60" href="/img/apple-touch-icon-60x60.png" id="light6">
    <!-- dark mode favicons -->
    <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16-dark.png" id="dark1">
    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32-dark.png" id="dark2">
    <link rel="apple-touch-icon" type="image/png" sizes="180x180" href="/img/apple-touch-icon-dark.png" id="dark3">
    <link rel="apple-touch-icon" type="image/png" sizes="120x120" href="/img/apple-touch-icon-120x120-dark.png" id="dark4">
    <link rel="apple-touch-icon" type="image/png" sizes="76x76" href="/img/apple-touch-icon-76x76-dark.png" id="dark5">
    <link rel="apple-touch-icon" type="image/png" sizes="60x60" href="/img/apple-touch-icon-60x60-dark.png" id="dark6">

    <script>
      // Switch to the dark-mode favicons if prefers-color-scheme: dark
      function onUpdate() {
        light1 = document.querySelector('link#light1');
        light2 = document.querySelector('link#light2');
        light3 = document.querySelector('link#light3');
        light4 = document.querySelector('link#light4');
        light5 = document.querySelector('link#light5');
        light6 = document.querySelector('link#light6');

        dark1 = document.querySelector('link#dark1');
        dark2 = document.querySelector('link#dark2');
        dark3 = document.querySelector('link#dark3');
        dark4 = document.querySelector('link#dark4');
        dark5 = document.querySelector('link#dark5');
        dark6 = document.querySelector('link#dark6');

        if (matcher.matches) {
          light1.remove();
          light2.remove();
          light3.remove();
          light4.remove();
          light5.remove();
          light6.remove();
          document.head.append(dark1);
          document.head.append(dark2);
          document.head.append(dark3);
          document.head.append(dark4);
          document.head.append(dark5);
          document.head.append(dark6);
        } else {
          dark1.remove();
          dark2.remove();
          dark3.remove();
          dark4.remove();
          dark5.remove();
          dark6.remove();
          document.head.append(light1);
          document.head.append(light2);
          document.head.append(light3);
          document.head.append(light4);
          document.head.append(light5);
          document.head.append(light6);
        }
      }
      matcher = window.matchMedia('(prefers-color-scheme: dark)');
      matcher.addListener(onUpdate);
      onUpdate();
    </script>

    <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic,900">

    <link href="/css/main.css" rel="stylesheet">
    <link href="/css/syntax.css" rel="stylesheet">
    <script src="/javascript/main.js"></script>
    
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107500873-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-107500873-1');
</script>

    
  </head>


<body class="wrap">
  <header>
    <nav class="navbar navbar-expand-md navbar-dark bg-dark">
  
  <a class="navbar-brand no-padding" href="/"><img src="/img/arrow-inverse-300px.png" height="40px"/></a>
  
   <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#arrow-navbar" aria-controls="arrow-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse justify-content-end" id="arrow-navbar">
      <ul class="nav navbar-nav">
        <li class="nav-item"><a class="nav-link" href="/overview/" role="button" aria-haspopup="true" aria-expanded="false">Overview</a></li>
        <li class="nav-item"><a class="nav-link" href="/faq/" role="button" aria-haspopup="true" aria-expanded="false">FAQ</a></li>
        <li class="nav-item"><a class="nav-link" href="/blog" role="button" aria-haspopup="true" aria-expanded="false">Blog</a></li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#"
             id="navbarDropdownGetArrow" role="button" data-toggle="dropdown"
             aria-haspopup="true" aria-expanded="false">
             Get Arrow
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownGetArrow">
            <a class="dropdown-item" href="/install/">Install</a>
            <a class="dropdown-item" href="/release/">Releases</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow">Source Code</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#"
             id="navbarDropdownDocumentation" role="button" data-toggle="dropdown"
             aria-haspopup="true" aria-expanded="false">
             Documentation
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownDocumentation">
            <a class="dropdown-item" href="/docs">Project Docs</a>
            <a class="dropdown-item" href="/docs/format/Columnar.html">Format</a>
            <hr/>
            <a class="dropdown-item" href="/docs/c_glib">C GLib</a>
            <a class="dropdown-item" href="/docs/cpp">C++</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/blob/master/csharp/README.md">C#</a>
            <a class="dropdown-item" href="https://godoc.org/github.com/apache/arrow/go/arrow">Go</a>
            <a class="dropdown-item" href="/docs/java">Java</a>
            <a class="dropdown-item" href="/docs/js">JavaScript</a>
            <a class="dropdown-item" href="https://arrow.juliadata.org/stable/">Julia</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/blob/master/matlab/README.md">MATLAB</a>
            <a class="dropdown-item" href="/docs/python">Python</a>
            <a class="dropdown-item" href="/docs/r">R</a>
            <a class="dropdown-item" href="https://github.com/apache/arrow/blob/master/ruby/README.md">Ruby</a>
            <a class="dropdown-item" href="https://docs.rs/crate/arrow/">Rust</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#"
             id="navbarDropdownSubprojects" role="button" data-toggle="dropdown"
             aria-haspopup="true" aria-expanded="false">
             Subprojects
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownSubprojects">
            <a class="dropdown-item" href="/datafusion">DataFusion</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#"
             id="navbarDropdownCommunity" role="button" data-toggle="dropdown"
             aria-haspopup="true" aria-expanded="false">
             Community
          </a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdownCommunity">
            <a class="dropdown-item" href="/community/">Communication</a>
            <a class="dropdown-item" href="/docs/developers/contributing.html">Contributing</a>
            <a class="dropdown-item" href="https://issues.apache.org/jira/browse/ARROW">Issue Tracker</a>
            <a class="dropdown-item" href="/committers/">Governance</a>
            <a class="dropdown-item" href="/use_cases/">Use Cases</a>
            <a class="dropdown-item" href="/powered_by/">Powered By</a>
            <a class="dropdown-item" href="/security/">Security</a>
            <a class="dropdown-item" href="https://www.apache.org/foundation/policies/conduct.html">Code of Conduct</a>
          </div>
        </li>
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="#"
             id="navbarDropdownASF" role="button" data-toggle="dropdown"
             aria-haspopup="true" aria-expanded="false">
             ASF Links
          </a>
          <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownASF">
            <a class="dropdown-item" href="http://www.apache.org/">ASF Website</a>
            <a class="dropdown-item" href="http://www.apache.org/licenses/">License</a>
            <a class="dropdown-item" href="http://www.apache.org/foundation/sponsorship.html">Donate</a>
            <a class="dropdown-item" href="http://www.apache.org/foundation/thanks.html">Thanks</a>
            <a class="dropdown-item" href="http://www.apache.org/security/">Security</a>
          </div>
        </li>
      </ul>
    </div><!-- /.navbar-collapse -->
  </nav>

  </header>

  <div class="container p-4 pt-5">
    <div class="col-md-8 mx-auto">
      <main role="main" class="pb-5">
        
<h1>
  Faster, scalable memory allocations in Apache Arrow with jemalloc
</h1>
<hr class="mt-4 mb-3">



<p class="mb-4 pb-1">
  <span class="badge badge-secondary">Published</span>
  <span class="published mr-3">
    20 Jul 2018
  </span>
  <br />
  <span class="badge badge-secondary">By</span>
  
    <a class="mr-3" href="https://github.com/xhochy">Uwe Korn (uwe) </a>
  

  
</p>


        <!--

-->

<p>With the release of the 0.9 version of Apache Arrow, we have switched our
default allocator for array buffers from the system allocator to jemalloc on
OSX and Linux. This applies to the C++/GLib/Python implementations of Arrow.
In most cases changing the default allocator is normally done to avoid problems
that occur with many small, frequent (de)allocations. In contrast, in Arrow we
normally deal with large in-memory datasets. While jemalloc provides good
strategies for <a href="https://zapier.com/engineering/celery-python-jemalloc/">avoiding RAM fragmentation for allocations that are lower than
a memory page (4kb)</a>, it also provides functionality that improves
performance on allocations that span several memory pages.</p>

<p>Outside of Apache Arrow, <a href="https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919/">jemalloc powers the infrastructure of Facebook</a>
(this is also where most of its development happens). It is also used as the
<a href="https://github.com/rust-lang/rust/pull/6895">default allocator in Rust</a> as well as it helps <a href="http://download.redis.io/redis-stable/README.md">Redis reduce the memory
fragmentation on Linux</a> (“Allocator”).</p>

<p>One allocation specialty that we require in Arrow is that memory should be
64byte aligned. This is so that we can get the most performance out of SIMD
instruction sets like AVX. While the most modern SIMD instructions also work on
unaligned memory, their performance is much better on aligned memory. To get the
best performance for our analytical applications, we want all memory to be
allocated such that SIMD performance is maximized.</p>

<p>For aligned allocations, the POSIX APIs only provide the
<code class="language-plaintext highlighter-rouge">aligned_alloc(void** ptr, size_t alignment, size_t size)</code> function to
allocate aligned memory. There is also 
<code class="language-plaintext highlighter-rouge">posix_memalign(void **ptr, size_t alignment, size_t size)</code> to modify an
allocation to the preferred alignment. But neither of them cater for expansions
of the allocation. While the <code class="language-plaintext highlighter-rouge">realloc</code> function can often expand allocations
without moving them physically, it does not ensure that in the case the
allocation is moved that the alignment is kept.</p>

<p>In the case when Arrow was built without jemalloc being enabled, this resulted
in copying the data on each new expansion of an allocation. To reduce the number
of memory copies, we use jemalloc’s <code class="language-plaintext highlighter-rouge">*allocx()</code>-APIs to create, modify and free
aligned allocations. One of the typical tasks where this gives us a major
speedup is on the incremental construction of an Arrow table that consists of
several columns. We often don’t know the size of the table in advance and need
to expand our allocations as the data is loaded.</p>

<p>To incrementally build a vector using memory expansion of a factor of 2, we
would use the following C-code with the standard POSIX APIs:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">size_t</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">128</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">;</span>
<span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">aligned_alloc</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">size_t</span> <span class="n">new_size</span> <span class="o">=</span> <span class="n">size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span>
  <span class="kt">void</span><span class="o">*</span> <span class="n">ptr2</span> <span class="o">=</span> <span class="n">aligned_alloc</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">new_size</span><span class="p">);</span>
  <span class="n">memcpy</span><span class="p">(</span><span class="n">ptr2</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
  <span class="n">free</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
  <span class="n">ptr</span> <span class="o">=</span> <span class="n">ptr2</span><span class="p">;</span>
  <span class="n">size</span> <span class="o">=</span> <span class="n">new_size</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">free</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
</code></pre></div></div>

<p>With jemalloc’s special APIs, we are able to omit the explicit call to <code class="language-plaintext highlighter-rouge">memcpy</code>.
In the case where a memory expansion cannot be done in-place, it is still called
by the allocator but not needed on all occasions. This simplifies our user code
to:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">size_t</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">128</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">;</span>
<span class="kt">void</span><span class="o">*</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">mallocx</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">MALLOCX_ALIGN</span><span class="p">(</span><span class="mi">64</span><span class="p">));</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">size</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">;</span>
  <span class="n">ptr</span> <span class="o">=</span> <span class="n">rallocx</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">MALLOCX_ALIGN</span><span class="p">(</span><span class="mi">64</span><span class="p">));</span>
<span class="p">}</span>
<span class="n">dallocx</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">MALLOCX_ALIGN</span><span class="p">(</span><span class="mi">64</span><span class="p">));</span>
</code></pre></div></div>

<p>To see the real world benefits of using jemalloc, we look at the benchmarks in
Arrow C++. There we have modeled a typical use case of incrementally building up
an array of primitive values. For the build-up of the array, we don’t know the
number of elements in the final array so we need to continuously expand the
memory region in which the data is stored. The code for this benchmark is part
of the <code class="language-plaintext highlighter-rouge">builder-benchmark</code> in the Arrow C++ sources as
<code class="language-plaintext highlighter-rouge">BuildPrimitiveArrayNoNulls</code>.</p>

<p>Runtimes without <code class="language-plaintext highlighter-rouge">jemalloc</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BM_BuildPrimitiveArrayNoNulls/repeats:3                 636726 us   804.114MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 621345 us   824.019MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 625008 us    819.19MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_mean            627693 us   815.774MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_median          625008 us    819.19MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev            8034 us   10.3829MB/s
</code></pre></div></div>

<p>Runtimes with <code class="language-plaintext highlighter-rouge">jemalloc</code>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BM_BuildPrimitiveArrayNoNulls/repeats:3                 630881 us   811.563MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 352891 us   1.41687GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 351039 us   1.42434GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_mean            444937 us   1.21125GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_median          352891 us   1.41687GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev          161035 us   371.335MB/s
</code></pre></div></div>

<p>The benchmark was run three times for each configuration to see the performance
differences. The first run in each configuration yielded the same performance but
in all subsequent runs, the version using jemalloc was about twice as fast. In
these cases, the memory region that was used for constructing the array could be
expanded in place without moving the data around. This was possible as there
were memory pages assigned to the process that were unused but not reclaimed by
the operating system. Without <code class="language-plaintext highlighter-rouge">jemalloc</code>, we cannot make use of them simply by
the fact that the default allocator has no API that provides aligned
reallocation.</p>


      </main>
    </div>

    <hr/>
<footer class="footer">
  <div class="row">
    <div class="col-md-9">
      <p>Apache Arrow, Arrow, Apache, the Apache feather logo, and the Apache Arrow project logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
      <p>&copy; 2016-2022 The Apache Software Foundation</p>
    </div>
    <div class="col-md-3">
      <a class="d-sm-none d-md-inline pr-2" href="https://www.apache.org/events/current-event.html">
        <img src="https://www.apache.org/events/current-event-234x60.png"/>
      </a>
    </div>
  </div>
</footer>

  </div>
</body>
</html>
