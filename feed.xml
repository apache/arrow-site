<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2019-04-02T12:38:19-04:00</updated><id>/feed.xml</id><entry><title type="html">Apache Arrow 0.13.0 Release</title><link href="/blog/2019/04/02/0.13.0-release/" rel="alternate" type="text/html" title="Apache Arrow 0.13.0 Release" /><published>2019-04-02T09:00:00-04:00</published><updated>2019-04-02T09:00:00-04:00</updated><id>/blog/2019/04/02/0.13.0-release</id><content type="html" xml:base="/blog/2019/04/02/0.13.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 0.13.0 release. This covers
more than 2 months of development work and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20%3D%20Resolved%20AND%20fixVersion%20%3D%200.13.0&quot;&gt;&lt;strong&gt;550 resolved
issues&lt;/strong&gt;&lt;/a&gt; from &lt;a href=&quot;https://arrow.apache.org/release/0.13.0.html#contributors&quot;&gt;&lt;strong&gt;81 distinct contributors&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://arrow.apache.org/install&quot;&gt;Install Page&lt;/a&gt; to learn how to get the libraries for your
platform. The &lt;a href=&quot;https://arrow.apache.org/release/0.13.0.html&quot;&gt;complete changelog&lt;/a&gt; is also available.&lt;/p&gt;

&lt;p&gt;While it’s a large release, this post will give some brief highlights in the
project since the 0.12.0 release from January.&lt;/p&gt;

&lt;h2 id=&quot;new-committer-and-pmc-member&quot;&gt;New committer and PMC member&lt;/h2&gt;

&lt;p&gt;The Arrow team is growing! Since the 0.12.0 release we have increased the size
of our committer and PMC rosters.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/andygrove&quot;&gt;Andy Grove&lt;/a&gt; was promoted to PMC member&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/emkornfield&quot;&gt;Micah Kornfield&lt;/a&gt; was added as a committer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thank you for all your contributions!&lt;/p&gt;

&lt;h2 id=&quot;rust-datafusion-query-engine-donation&quot;&gt;Rust DataFusion Query Engine donation&lt;/h2&gt;

&lt;p&gt;Since the last release, we received a donation of &lt;a href=&quot;http://incubator.apache.org/ip-clearance/arrow-rust-datafusion.html&quot;&gt;DataFusion&lt;/a&gt;, a
Rust-native query engine for the Arrow columnar format, whose development had
been led prior by Andy Grove. &lt;a href=&quot;http://arrow.apache.org/blog/2019/02/04/datafusion-donation/&quot;&gt;Read more about DataFusion&lt;/a&gt; in our February
blog post.&lt;/p&gt;

&lt;p&gt;This is an exciting development for the Rust community, and we look forward to
developing more analytical query processing within the Apache Arrow project.&lt;/p&gt;

&lt;h2 id=&quot;arrow-flight-grpc-progress&quot;&gt;Arrow Flight gRPC progress&lt;/h2&gt;

&lt;p&gt;Over the last couple months, we have made significant progress on Arrow Flight,
an Arrow-native data messaging framework. We have integration tests to check
C++ and Java compatibility, and we have added Python bindings for the C++
library. We will write a future blog post to go into more detail about how
Flight works.&lt;/p&gt;

&lt;h2 id=&quot;c-notes&quot;&gt;C++ notes&lt;/h2&gt;

&lt;p&gt;There were 231 issues relating to C++ in this release, far too much to
summarize in a blog post. Some notable items include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An experimental &lt;code class=&quot;highlighter-rouge&quot;&gt;ExtensionType&lt;/code&gt; was developed for creating user-defined data
types that can be embedded in the Arrow binary protocol. This is not yet
finalized, but &lt;a href=&quot;https://github.com/apache/arrow/blob/master/cpp/src/arrow/extension_type.h&quot;&gt;feedback would be welcome&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;We have undertaken a significant reworking of our CMake build system for C++
to make the third party dependencies more configurable. Among other things,
this eases work on packaging for Linux distributions. Read more about this in
the &lt;a href=&quot;https://github.com/apache/arrow/blob/master/docs/source/developers/cpp.rst#build-dependency-management&quot;&gt;C++ developer documentation&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Laying more groundwork for an Arrow-native in-memory query engine&lt;/li&gt;
  &lt;li&gt;We began building a reader for line-delimited JSON files&lt;/li&gt;
  &lt;li&gt;Gandiva can now be compiled on Windows with Visual Studio&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;c-notes-1&quot;&gt;C# Notes&lt;/h2&gt;

&lt;p&gt;C# .NET development has picked up since the initial code donation last
fall. 11 issues were resolved this release cycle.&lt;/p&gt;

&lt;p&gt;The Arrow C# package is &lt;a href=&quot;https://www.nuget.org/packages/Apache.Arrow/0.13.0&quot;&gt;now available via NuGet&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;go-notes&quot;&gt;Go notes&lt;/h2&gt;

&lt;p&gt;8 Go-related issues were resolved. A notable feature is the addition of a CSV
file writer.&lt;/p&gt;

&lt;h2 id=&quot;java-notes&quot;&gt;Java notes&lt;/h2&gt;

&lt;p&gt;26 Java issues were resolved. Outside of Flight-related work, some notable
items include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Migration to Java 8 date and time APIs from Joda&lt;/li&gt;
  &lt;li&gt;Array type support in JDBC adapter&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;javascript-notes&quot;&gt;Javascript Notes&lt;/h2&gt;

&lt;p&gt;The recent &lt;a href=&quot;https://www.npmjs.com/package/apache-arrow/v/0.4.1&quot;&gt;JavaScript 0.4.1 release&lt;/a&gt; is the last JavaScript-only release
of Apache Arrow. Starting with 0.13 the Javascript implementation is now
included in mainline Arrow releases! The version number of the released
JavaScript packages will now be in sync with the mainline version number.&lt;/p&gt;

&lt;h2 id=&quot;python-notes&quot;&gt;Python notes&lt;/h2&gt;

&lt;p&gt;86 Python-related issues were resolved. Some highlights include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Gandiva LLVM expression compiler is now available in the Python wheels
through the &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.gandiva&lt;/code&gt; module.&lt;/li&gt;
  &lt;li&gt;Flight RPC bindings&lt;/li&gt;
  &lt;li&gt;Improved pandas serialization performance with RangeIndex&lt;/li&gt;
  &lt;li&gt;pyarrow can be used without pandas installed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that Apache Arrow will continue to support Python 2.7 until January 2020.&lt;/p&gt;

&lt;h2 id=&quot;ruby-and-c-glib-notes&quot;&gt;Ruby and C GLib notes&lt;/h2&gt;

&lt;p&gt;36 C/GLib- and Ruby-related issues were resolved. The work continues to follow
the upstream work in the C++ project.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Arrow::RecordBatch#raw_records&lt;/code&gt; was added. It can convert a record batch to
a Ruby’s array in 10x-200x faster than the same conversion by a pure-Ruby
implementation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rust-notes&quot;&gt;Rust notes&lt;/h2&gt;

&lt;p&gt;69 Rust-related issues were resolved. Many of these relate to ongoing work in
the DataFusion query engine. Some notable items include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Date/time support&lt;/li&gt;
  &lt;li&gt;SIMD for arithmetic operations&lt;/li&gt;
  &lt;li&gt;Writing CSV and reading line-delimited JSON&lt;/li&gt;
  &lt;li&gt;Parquet data source support for DataFusion&lt;/li&gt;
  &lt;li&gt;Prototype DataFrame-style API for DataFusion&lt;/li&gt;
  &lt;li&gt;Continued evolution of Parquet file reader&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;r-development-progress&quot;&gt;R development progress&lt;/h2&gt;

&lt;p&gt;The Arrow R developers have expanded the scope of the R language bindings and
additionally worked on packaging support to be able to submit the package to
CRAN in the near future. 23 issues were resolved for this release.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://arrow.apache.org/blog/2019/01/25/r-spark-improvements/&quot;&gt;We wrote in January about ongoing work&lt;/a&gt; to accelerate R work on Apache Spark
using Arrow.&lt;/p&gt;

&lt;h2 id=&quot;community-discussions-ongoing&quot;&gt;Community Discussions Ongoing&lt;/h2&gt;

&lt;p&gt;There are a number of active discussions ongoing on the developer
&lt;code class=&quot;highlighter-rouge&quot;&gt;dev@arrow.apache.org&lt;/code&gt; mailing list. We look forward to hearing from the
community there:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Benchmarking&lt;/strong&gt;: we are working to create tools for tracking all of our
benchmark results on a commit-by-commit basis in a centralized database
schema so that we can monitor for performance regressions over time. We hope
to develop a publicly viewable benchmark result dashboard.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;C++ Datasets&lt;/strong&gt;: development of a unified API for reading and writing
datasets stored in various common formats like Parquet, JSON, and CSV.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;C++ Query Engine&lt;/strong&gt;: architecture of a parallel Arrow-native query engine
for C++&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arrow Flight Evolution&lt;/strong&gt;: adding features to support different real-world
data messaging use cases&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Arrow Columnar Format evolution&lt;/strong&gt;: we are discussing a new “duration” or
“time interval” type and some other additions to the Arrow columnar format.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>wesm</name></author></entry><entry><title type="html">Reducing Python String Memory Use in Apache Arrow 0.12</title><link href="/blog/2019/02/05/python-string-memory-0.12/" rel="alternate" type="text/html" title="Reducing Python String Memory Use in Apache Arrow 0.12" /><published>2019-02-05T08:00:00-05:00</published><updated>2019-02-05T08:00:00-05:00</updated><id>/blog/2019/02/05/python-string-memory-0.12</id><content type="html" xml:base="/blog/2019/02/05/python-string-memory-0.12/">&lt;!--

--&gt;

&lt;p&gt;Python users who upgrade to recently released &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; 0.12 may find that
their applications use significantly less memory when converting Arrow string
data to pandas format. This includes using &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.parquet.read_table&lt;/code&gt; and
&lt;code class=&quot;highlighter-rouge&quot;&gt;pandas.read_parquet&lt;/code&gt;. This article details some of what is going on under the
hood, and why Python applications dealing with large amounts of strings are
prone to memory use problems.&lt;/p&gt;

&lt;h2 id=&quot;why-python-strings-can-use-a-lot-of-memory&quot;&gt;Why Python strings can use a lot of memory&lt;/h2&gt;

&lt;p&gt;Let’s start with some possibly surprising facts. I’m going to create an empty
&lt;code class=&quot;highlighter-rouge&quot;&gt;bytes&lt;/code&gt; object and an empty &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt; (unicode) object in Python 3.7:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [1]: val = b''

In [2]: unicode_val = u''
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;sys.getsizeof&lt;/code&gt; function accurately reports the number of bytes used by
built-in Python objects. You might be surprised to find that:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [4]: import sys
In [5]: sys.getsizeof(val)
Out[5]: 33

In [6]: sys.getsizeof(unicode_val)
Out[6]: 49
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since strings in Python are nul-terminated, we can infer that a bytes object
has 32 bytes of overhead while unicode has 48 bytes. One must also account for
&lt;code class=&quot;highlighter-rouge&quot;&gt;PyObject*&lt;/code&gt; pointer references to the objects, so the actual overhead is 40 and
56 bytes, respectively. With large strings and text, this overhead may not
matter much, but when you have a lot of small strings, such as those arising
from reading a CSV or Apache Parquet file, they can take up an unexpected
amount of memory. pandas represents strings in NumPy arrays of &lt;code class=&quot;highlighter-rouge&quot;&gt;PyObject*&lt;/code&gt;
pointers, so the total memory used by a unique unicode string is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;8 (PyObject*) + 48 (Python C struct) + string_length + 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Suppose that we read a CSV file with&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1 column&lt;/li&gt;
  &lt;li&gt;1 million rows&lt;/li&gt;
  &lt;li&gt;Each value in the column is a string with 10 characters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On disk this file would take approximately 10MB. Read into memory, however, it
could take up over 60MB, as a 10 character string object takes up 67 bytes in a
&lt;code class=&quot;highlighter-rouge&quot;&gt;pandas.Series&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;how-apache-arrow-represents-strings&quot;&gt;How Apache Arrow represents strings&lt;/h2&gt;

&lt;p&gt;While a Python unicode string can have 57 bytes of overhead, a string in the
Arrow columnar format has only 4 (32 bits) or 4.125 (33 bits) bytes of
overhead. 32-bit integer offsets encodes the position and size of a string
value in a contiguous chunk of memory:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/20190205-arrow-string.png&quot; alt=&quot;Apache Arrow string memory layout&quot; width=&quot;80%&quot; class=&quot;img-responsive&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;When you call &lt;code class=&quot;highlighter-rouge&quot;&gt;table.to_pandas()&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;array.to_pandas()&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt;, we
have to convert this compact string representation back to pandas’s
Python-based strings. This can use a huge amount of memory when we have a large
number of small strings. It is a quite common occurrence when working with web
analytics data, which compresses to a compact size when stored in the Parquet
columnar file format.&lt;/p&gt;

&lt;p&gt;Note that the Arrow string memory format has other benefits beyond memory
use. It is also much more efficient for analytics due to the guarantee of data
locality; all strings are next to each other in memory. In the case of pandas
and Python strings, the string data can be located anywhere in the process
heap. Arrow PMC member Uwe Korn did some work to &lt;a href=&quot;https://www.slideshare.net/xhochy/extending-pandas-using-apache-arrow-and-numba&quot;&gt;extend pandas with Arrow
string arrays&lt;/a&gt; for improved performance and memory use.&lt;/p&gt;

&lt;h2 id=&quot;reducing-pandas-memory-use-when-converting-from-arrow&quot;&gt;Reducing pandas memory use when converting from Arrow&lt;/h2&gt;

&lt;p&gt;For many years, the &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas.read_csv&lt;/code&gt; function has relied on a trick to limit
the amount of string memory allocated. Because pandas uses arrays of
&lt;code class=&quot;highlighter-rouge&quot;&gt;PyObject*&lt;/code&gt; pointers to refer to objects in the Python heap, we can avoid
creating multiple strings with the same value, instead reusing existing objects
and incrementing their reference counts.&lt;/p&gt;

&lt;p&gt;Schematically, we have the following:&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/20190205-numpy-string.png&quot; alt=&quot;pandas string memory optimization&quot; width=&quot;80%&quot; class=&quot;img-responsive&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; 0.12, we have implemented this when calling &lt;code class=&quot;highlighter-rouge&quot;&gt;to_pandas&lt;/code&gt;. It
requires using a hash table to deduplicate the Arrow string data as it’s being
converted to pandas. Hashing data is not free, but counterintuitively it can be
faster in addition to being vastly more memory efficient in the common case in
analytics where we have table columns with many instances of the same string
values.&lt;/p&gt;

&lt;h2 id=&quot;memory-and-performance-benchmarks&quot;&gt;Memory and Performance Benchmarks&lt;/h2&gt;

&lt;p&gt;We can use the &lt;a href=&quot;https://pypi.org/project/memory-profiler/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;memory_profiler&lt;/code&gt;&lt;/a&gt; Python package to easily get process
memory usage within a running Python application.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;memory_profiler&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;memory_profiler&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory_usage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In a new application I have:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [7]: mem()
Out[7]: 86.21875
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I will generate approximate 1 gigabyte of string data represented as Python
strings with length 10. The &lt;code class=&quot;highlighter-rouge&quot;&gt;pandas.util.testing&lt;/code&gt; module has a handy &lt;code class=&quot;highlighter-rouge&quot;&gt;rands&lt;/code&gt;
function for generating random strings. Here is the data generation function:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas.util.testing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rands&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_strings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nunique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;unique_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rands&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nunique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unique_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nunique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This generates a certain number of unique strings, then duplicates then to
yield the desired number of total strings. So I’m going to create 100 million
strings with only 10000 unique values:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [8]: values = generate_strings(100000000, 10000)

In [9]: mem()
Out[9]: 852.140625
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;100 million &lt;code class=&quot;highlighter-rouge&quot;&gt;PyObject*&lt;/code&gt; values is only 745 MB, so this increase of a little
over 770 MB is consistent with what we know so far. Now I’m going to convert
this to Arrow format:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [11]: arr = pa.array(values)

In [12]: mem()
Out[12]: 2276.9609375
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow&lt;/code&gt; exactly accounts for all of its memory allocations, we also
check that&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [13]: pa.total_allocated_bytes()
Out[13]: 1416777280
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Since each string takes about 14 bytes (10 bytes plus 4 bytes of overhead),
this is what we expect.&lt;/p&gt;

&lt;p&gt;Now, converting &lt;code class=&quot;highlighter-rouge&quot;&gt;arr&lt;/code&gt; back to pandas is where things get tricky. The &lt;em&gt;minimum&lt;/em&gt;
amount of memory that pandas can use is a little under 800 MB as above as we
need 100 million &lt;code class=&quot;highlighter-rouge&quot;&gt;PyObject*&lt;/code&gt; values, which are 8 bytes each.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [14]: arr_as_pandas = arr.to_pandas()

In [15]: mem()
Out[15]: 3041.78125
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Doing the math, we used 765 MB which seems right. We can disable the string
deduplication logic by passing &lt;code class=&quot;highlighter-rouge&quot;&gt;deduplicate_objects=False&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;to_pandas&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [16]: arr_as_pandas_no_dedup = arr.to_pandas(deduplicate_objects=False)

In [17]: mem()
Out[17]: 10006.95703125
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Without object deduplication, we use 6965 megabytes, or an average of 73 bytes
per value. This is a little bit higher than the theoretical size of 67 bytes
computed above.&lt;/p&gt;

&lt;p&gt;One of the more surprising results is that the new behavior is about twice as fast:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;In [18]: %time arr_as_pandas_time = arr.to_pandas()
CPU times: user 2.94 s, sys: 213 ms, total: 3.15 s
Wall time: 3.14 s

In [19]: %time arr_as_pandas_no_dedup_time = arr.to_pandas(deduplicate_objects=False)
CPU times: user 4.19 s, sys: 2.04 s, total: 6.23 s
Wall time: 6.21 s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reason for this is that creating so many Python objects is more expensive
than hashing the 10 byte values and looking them up in a hash table.&lt;/p&gt;

&lt;p&gt;Note that when you convert Arrow data with mostly unique values back to pandas,
the memory use benefits here won’t have as much of an impact.&lt;/p&gt;

&lt;h2 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h2&gt;

&lt;p&gt;In Apache Arrow, our goal is to develop computational tools to operate natively
on the cache- and SIMD-friendly efficient Arrow columnar format. In the
meantime, though, we recognize that users have legacy applications using the
native memory layout of pandas or other analytics tools. We will do our best to
provide fast and memory-efficient interoperability with pandas and other
popular libraries.&lt;/p&gt;</content><author><name>wesm</name></author></entry><entry><title type="html">DataFusion: A Rust-native Query Engine for Apache Arrow</title><link href="/blog/2019/02/04/datafusion-donation/" rel="alternate" type="text/html" title="DataFusion: A Rust-native Query Engine for Apache Arrow" /><published>2019-02-04T01:00:00-05:00</published><updated>2019-02-04T01:00:00-05:00</updated><id>/blog/2019/02/04/datafusion-donation</id><content type="html" xml:base="/blog/2019/02/04/datafusion-donation/">&lt;!--

--&gt;

&lt;p&gt;We are excited to announce that &lt;a href=&quot;https://github.com/apache/arrow/tree/master/rust/datafusion&quot;&gt;DataFusion&lt;/a&gt; has been donated to the Apache Arrow project. DataFusion is an in-memory query engine for the Rust implementation of Apache Arrow.&lt;/p&gt;

&lt;p&gt;Although DataFusion was started two years ago, it was recently re-implemented to be Arrow-native and currently has limited capabilities but does support SQL queries against iterators of RecordBatch and has support for CSV files. There are plans to &lt;a href=&quot;https://issues.apache.org/jira/browse/ARROW-4466&quot;&gt;add support for Parquet files&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;SQL support is limited to projection (&lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;), selection (&lt;code class=&quot;highlighter-rouge&quot;&gt;WHERE&lt;/code&gt;), and simple aggregates (&lt;code class=&quot;highlighter-rouge&quot;&gt;MIN&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;MAX&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;SUM&lt;/code&gt;) with an optional &lt;code class=&quot;highlighter-rouge&quot;&gt;GROUP BY&lt;/code&gt; clause.&lt;/p&gt;

&lt;p&gt;Supported expressions are identifiers, literals, simple math operations (&lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt;), binary expressions (&lt;code class=&quot;highlighter-rouge&quot;&gt;AND&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;OR&lt;/code&gt;), equality and comparison operators (&lt;code class=&quot;highlighter-rouge&quot;&gt;=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;!=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt;), and &lt;code class=&quot;highlighter-rouge&quot;&gt;CAST(expr AS type)&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;The following example demonstrates running a simple aggregate SQL query against a CSV file.&lt;/p&gt;

&lt;div class=&quot;language-rust highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;// create execution context&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;// define schema for data source (csv file)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Arc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;Schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;vec!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utf8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UInt32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c4&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c5&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c7&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UInt8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c8&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UInt16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c9&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UInt32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c10&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UInt64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c11&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c12&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Float64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;c13&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DataType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Utf8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]));&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;// register csv file with the execution context&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv_datasource&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;nn&quot;&gt;CsvDataSource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test/data/aggregate_test_100.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.register_datasource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aggregate_test_100&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Rc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nn&quot;&gt;RefCell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csv_datasource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;SELECT c1, MIN(c12), MAX(c12) FROM aggregate_test_100 WHERE c11 &amp;gt; 0.1 AND c11 &amp;lt; 0.9 GROUP BY c1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;// execute the query&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ctx&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relation&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.borrow_mut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;// iterate over the results&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;println!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;RecordBatch has {} rows and {} columns&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.num_rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.num_columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.as_any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;py&quot;&gt;.downcast_ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BinaryArray&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.as_any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;py&quot;&gt;.downcast_ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Float64Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.as_any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;py&quot;&gt;.downcast_ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Float64Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.num_rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;from_utf8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.to_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nd&quot;&gt;println!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{}, Min: {}, Max: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;.value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;roadmap&quot;&gt;Roadmap&lt;/h2&gt;

&lt;p&gt;The roadmap for DataFusion will depend on interest from the Rust community, but here are some of the short term items that are planned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Extending test coverage of the existing functionality&lt;/li&gt;
  &lt;li&gt;Adding support for Parquet data sources&lt;/li&gt;
  &lt;li&gt;Implementing more SQL features such as &lt;code class=&quot;highlighter-rouge&quot;&gt;JOIN&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ORDER BY&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;LIMIT&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Implement a DataFrame API as an alternative to SQL&lt;/li&gt;
  &lt;li&gt;Adding support for partitioning and parallel query execution using Rust’s async and await functionality&lt;/li&gt;
  &lt;li&gt;Creating a Docker image to make it easy to use DataFusion as a standalone query tool for interactive and batch queries&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;contributors-welcome&quot;&gt;Contributors Welcome!&lt;/h2&gt;

&lt;p&gt;If you are excited about being able to use Rust for data science and would like to contribute to this work then there are many ways to get involved. The simplest way to get started is to try out DataFusion against your own data sources and file bug reports for any issues that you find. You could also check out the current &lt;a href=&quot;https://cwiki.apache.org/confluence/display/ARROW/Rust+JIRA+Dashboard&quot;&gt;list of issues&lt;/a&gt; and have a go at fixing one. You can also join the &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/arrow-user/&quot;&gt;user mailing list&lt;/a&gt; to ask questions.&lt;/p&gt;</content><author><name>agrove</name></author></entry><entry><title type="html">Speeding up R and Apache Spark using Apache Arrow</title><link href="/blog/2019/01/25/r-spark-improvements/" rel="alternate" type="text/html" title="Speeding up R and Apache Spark using Apache Arrow" /><published>2019-01-25T01:00:00-05:00</published><updated>2019-01-25T01:00:00-05:00</updated><id>/blog/2019/01/25/r-spark-improvements</id><content type="html" xml:base="/blog/2019/01/25/r-spark-improvements/">&lt;!--

--&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/javierluraschi&quot;&gt;Javier Luraschi&lt;/a&gt; is a software engineer at &lt;a href=&quot;https://rstudio.com&quot;&gt;RStudio&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Support for Apache Arrow in Apache Spark with R is currently under active
development in the &lt;a href=&quot;https://github.com/rstudio/sparklyr&quot;&gt;sparklyr&lt;/a&gt; and &lt;a href=&quot;https://spark.apache.org/docs/latest/sparkr.html&quot;&gt;SparkR&lt;/a&gt; projects. This post explores early, yet
promising, performance improvements achieved when using R with &lt;a href=&quot;https://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt;,
Arrow and &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;/h1&gt;

&lt;p&gt;Since this work is under active development, install &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt; and
&lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; from GitHub as follows:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;devtools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install_github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;apache/arrow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subdir&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;r&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;apache-arrow-0.12.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;devtools&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;install_github&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;rstudio/sparklyr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;apache-arrow-0.12.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this benchmark, we will use &lt;a href=&quot;https://dplyr.tidyverse.org&quot;&gt;dplyr&lt;/a&gt;, but similar improvements can
be  expected from using &lt;a href=&quot;https://cran.r-project.org/package=DBI&quot;&gt;DBI&lt;/a&gt;, or &lt;a href=&quot;https://spark.rstudio.com/reference/#section-spark-dataframes&quot;&gt;Spark DataFrames&lt;/a&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;.
The local Spark connection and dataframe with 10M numeric rows was
initialized as follows:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dplyr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark_connect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;local&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;sparklyr.shell.driver-memory&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;6g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;copying&quot;&gt;Copying&lt;/h1&gt;

&lt;p&gt;Currently, copying data to Spark using &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt; is performed by persisting
data on-disk from R and reading it back from Spark. This was meant to be used
for small datasets since there are better tools to transfer data into
distributed storage systems. Nevertheless, many users have requested support to
transfer more data at fast speeds into Spark.&lt;/p&gt;

&lt;p&gt;Using &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;, we can transfer data directly from R to
Spark without having to serialize this data in R or persist in disk.&lt;/p&gt;

&lt;p&gt;The following example copies 10M rows from R into Spark using &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;
with and without &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt;, there is close to a 16x improvement using &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This benchmark uses the &lt;a href=&quot;https://CRAN.R-project.org/package=microbenchmark&quot;&gt;microbenchmark&lt;/a&gt; R package, which runs code
multiple times, provides stats on total execution time and plots each
excecution time to understand the distribution over each iteration.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_on&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_off&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arrow&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;package:arrow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;overwrite&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%T&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; Unit: seconds
      expr       min        lq       mean    median         uq       max neval
  arrow_on  3.011515  4.250025   7.257739  7.273011   8.974331  14.23325    10
 arrow_off 50.051947 68.523081 119.946947 71.898908 138.743419 390.44028    10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/arrow-r-spark-copying.png&quot; alt=&quot;Copying data with R into Spark with and without Arrow&quot; width=&quot;60%&quot; class=&quot;img-responsive&quot; /&gt;
&lt;/div&gt;

&lt;h1 id=&quot;collecting&quot;&gt;Collecting&lt;/h1&gt;

&lt;p&gt;Similarly, &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt; can now avoid deserializing data in R
while collecting data from Spark into R. These improvements are not as
significant as copying data since, &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt; already collects data in
columnar format.&lt;/p&gt;

&lt;p&gt;The following benchmark collects 10M rows from Spark into R and shows that
&lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; can bring 3x improvements.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_on&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_off&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arrow&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;package:arrow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%T&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Unit: seconds
      expr      min        lq      mean    median        uq       max neval
  arrow_on 4.520593  5.609812  6.154509  5.928099  6.217447  9.432221    10
 arrow_off 7.882841 13.358113 16.670708 16.127704 21.051382 24.373331    10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/arrow-r-spark-collecting.png&quot; alt=&quot;Collecting data with R from Spark with and without Arrow&quot; width=&quot;60%&quot; class=&quot;img-responsive&quot; /&gt;
&lt;/div&gt;

&lt;h1 id=&quot;transforming&quot;&gt;Transforming&lt;/h1&gt;

&lt;p&gt;Today, custom transformations of data using R functions are performed in
&lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt; by moving data in row-format from Spark into an R process through a
socket connection, transferring data in row-format is inefficient since
multiple data types need to be deserialized over each row, then the data gets
converted to columnar format (R was originally designed to use columnar data),
once R finishes this computation, data is again converted to row-format,
serialized row-by-row and then sent back to Spark over the socket connection.&lt;/p&gt;

&lt;p&gt;By adding support for &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;, it makes Spark perform the
row-format to column-format conversion in parallel in Spark. Data
is then transferred through the socket but no custom serialization takes place.
All the R process needs to do is copy this data from the socket into its heap,
transform it and copy it back to the socket connection.&lt;/p&gt;

&lt;p&gt;The following example transforms 100K rows with and without &lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; enabled,
&lt;code class=&quot;highlighter-rouge&quot;&gt;arrow&lt;/code&gt; makes transformation with R functions close to 41x faster.&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;microbenchmark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_on&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark_apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrow_off&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;arrow&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%in%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.packages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;package:arrow&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparklyr_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;^&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark_apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;.x&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;times&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%T&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&amp;gt;%&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ggplot2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Unit: seconds
      expr        min         lq       mean     median         uq        max neval
  arrow_on   3.881293   4.038376   5.136604   4.772739   5.759082   7.873711    10
 arrow_off 178.605733 183.654887 213.296238 227.182018 233.601885 238.877341    10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/arrow-r-spark-transforming.png&quot; alt=&quot;Transforming data with R in Spark with and without Arrow&quot; width=&quot;60%&quot; class=&quot;img-responsive&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Additional benchmarks and fine-tuning parameters can be found under &lt;code class=&quot;highlighter-rouge&quot;&gt;sparklyr&lt;/code&gt;
&lt;a href=&quot;https://github.com/rstudio/sparklyr/pull/1611&quot;&gt;/rstudio/sparklyr/pull/1611&lt;/a&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SparkR&lt;/code&gt; &lt;a href=&quot;https://github.com/apache/spark/pull/22954&quot;&gt;/apache/spark/pull/22954&lt;/a&gt;. Looking forward to bringing this feature
to the Spark, Arrow and R communities.&lt;/p&gt;</content><author><name>javierluraschi</name></author></entry><entry><title type="html">Apache Arrow 0.12.0 Release</title><link href="/blog/2019/01/21/0.12.0-release/" rel="alternate" type="text/html" title="Apache Arrow 0.12.0 Release" /><published>2019-01-21T08:00:00-05:00</published><updated>2019-01-21T08:00:00-05:00</updated><id>/blog/2019/01/21/0.12.0-release</id><content type="html" xml:base="/blog/2019/01/21/0.12.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 0.12.0 release. This is the
largest release yet in the project, covering 3 months of development work and
includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20in%20(Resolved%2C%20Closed)%20AND%20fixVersion%20%3D%200.12.0&quot;&gt;&lt;strong&gt;614 resolved issues&lt;/strong&gt;&lt;/a&gt; from &lt;a href=&quot;https://arrow.apache.org/release/0.12.0.html#contributors&quot;&gt;&lt;strong&gt;77 distinct contributors&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://arrow.apache.org/install&quot;&gt;Install Page&lt;/a&gt; to learn how to get the libraries for your
platform. The &lt;a href=&quot;https://arrow.apache.org/release/0.12.0.html&quot;&gt;complete changelog&lt;/a&gt; is also available.&lt;/p&gt;

&lt;p&gt;It’s a huge release, but we’ll give some brief highlights and new from the
project to help guide you to the parts of the project that may be of interest.&lt;/p&gt;

&lt;h2 id=&quot;new-committers-and-pmc-member&quot;&gt;New committers and PMC member&lt;/h2&gt;

&lt;p&gt;The Arrow team is growing! Since the 0.11.0 release we have added 3 new
committers:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/sbinet&quot;&gt;Sebastien Binet&lt;/a&gt;, who has mainly worked on the Go implementation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/romainfrancois&quot;&gt;Romain Francois&lt;/a&gt;, who has mainly worked on the R implementation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/shiro615&quot;&gt;Yosuke Shiro&lt;/a&gt;, who has mainly worked on the GLib (C) and Ruby
implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We also pleased to announce that &lt;a href=&quot;https://github.com/kszucs&quot;&gt;Krisztián Szűcs&lt;/a&gt; has been promoted
from committer to PMC (Project Management Committee) member.&lt;/p&gt;

&lt;p&gt;Thank you for all your contributions!&lt;/p&gt;

&lt;h2 id=&quot;code-donations&quot;&gt;Code donations&lt;/h2&gt;

&lt;p&gt;Since the last release, we have received 3 code donations into the Apache
project.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;a href=&quot;http://incubator.apache.org/ip-clearance/arrow-csharp-library.html&quot;&gt;native C# .NET library&lt;/a&gt; donated by Feyen Zylstra LLC.&lt;/li&gt;
  &lt;li&gt;A &lt;a href=&quot;http://incubator.apache.org/ip-clearance/arrow-parquet-ruby.html&quot;&gt;Ruby library for Parquet files&lt;/a&gt; which uses the existing GLib bindings to
the C++ Parquet library.&lt;/li&gt;
  &lt;li&gt;A &lt;a href=&quot;http://incubator.apache.org/ip-clearance/arrow-parquet-rust.html&quot;&gt;native Rust Parquet library&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We are excited to continue to grow the Apache Arrow development community.&lt;/p&gt;

&lt;h2 id=&quot;combined-project-level-documentation&quot;&gt;Combined project-level documentation&lt;/h2&gt;

&lt;p&gt;Since the last release, we have merged the Python and C++ documentation to
create a combined project-wide documentation site:
https://arrow.apache.org/docs. There is now some prose documentation about many
parts of the C++ library. We intend to keep adding documentation for other
parts of Apache Arrow to this site.&lt;/p&gt;

&lt;h2 id=&quot;packages&quot;&gt;Packages&lt;/h2&gt;

&lt;p&gt;We start providing the official APT and Yum repositories for C++ and
GLib (C). See the &lt;a href=&quot;https://arrow.apache.org/install/&quot;&gt;install document&lt;/a&gt; for details.&lt;/p&gt;

&lt;h2 id=&quot;c-notes&quot;&gt;C++ notes&lt;/h2&gt;

&lt;p&gt;Much of the C++ development work the last 3 months concerned internal code
refactoring and performance improvements. Some user-visible highlights of note:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Experimental support for &lt;a href=&quot;https://github.com/apache/arrow/blob/master/cpp/src/arrow/sparse_tensor.h&quot;&gt;in-memory sparse tensors (or ndarrays)&lt;/a&gt;, with
support for zero-copy IPC&lt;/li&gt;
  &lt;li&gt;Support for building on Alpine Linux&lt;/li&gt;
  &lt;li&gt;Significantly improved hash table utilities, with improved hash table
performance in many parts of the library&lt;/li&gt;
  &lt;li&gt;IO library improvements for both read and write buffering&lt;/li&gt;
  &lt;li&gt;A fast &lt;a href=&quot;https://github.com/apache/arrow/blob/master/cpp/src/arrow/util/trie.h&quot;&gt;trie implementation&lt;/a&gt; for string searching&lt;/li&gt;
  &lt;li&gt;Many improvements to the parallel CSV reader in performance and features. See
the changelog&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the LLVM-based Gandiva expression compiler was donated to Apache Arrow
during the last release cycle, development there has been moving along. We
expect to have Windows support for Gandiva and to ship this in downstream
packages (like Python) in the 0.13 release time frame.&lt;/p&gt;

&lt;h2 id=&quot;go-notes&quot;&gt;Go notes&lt;/h2&gt;

&lt;p&gt;The Arrow Go development team has been expanding. The Go library has gained
support for many missing features from the columnar format as well as semantic
constructs like chunked arrays and tables that are used heavily in the C++
project.&lt;/p&gt;

&lt;h2 id=&quot;glib-and-ruby-notes&quot;&gt;GLib and Ruby notes&lt;/h2&gt;

&lt;p&gt;Development of the GLib-based C bindings and corresponding Ruby interfaces have
advanced in lock-step with the C++, Python, and R libraries. In this release,
there are many new features in C and Ruby:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Compressed file read/write support&lt;/li&gt;
  &lt;li&gt;Support for using the C++ parallel CSV reader&lt;/li&gt;
  &lt;li&gt;Feather file support&lt;/li&gt;
  &lt;li&gt;Gandiva bindings&lt;/li&gt;
  &lt;li&gt;Plasma bindings&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python-notes&quot;&gt;Python notes&lt;/h2&gt;

&lt;p&gt;We fixed a ton of bugs and made many improvements throughout the Python
project. Some highlights from the Python side include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Python 3.7 support: wheels and conda packages are now available for Python
3.7&lt;/li&gt;
  &lt;li&gt;Substantially improved memory use when converting strings types to pandas
format, including when reading Parquet files. Parquet users should notice
significantly lower memory use in common use cases&lt;/li&gt;
  &lt;li&gt;Support for reading and writing compressed files, can be used for CSV files,
IPC, or any other form of IO&lt;/li&gt;
  &lt;li&gt;The new &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.input_stream&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.output_stream&lt;/code&gt; functions support
read and write buffering. This is analogous to &lt;code class=&quot;highlighter-rouge&quot;&gt;BufferedIOBase&lt;/code&gt; from the
Python standard library, but the internals are implemented natively in C++.&lt;/li&gt;
  &lt;li&gt;Gandiva (LLVM expression compiler) bindings, though not yet available in
pip/conda yet. Look for this in 0.13.0.&lt;/li&gt;
  &lt;li&gt;Many improvements to Arrow CUDA integration, including interoperability with
Numba&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;r-notes&quot;&gt;R notes&lt;/h2&gt;

&lt;p&gt;The R library made huge progress in 0.12, with work led by new committer Romain
Francois. The R project’s features are not far behind the Python library, and
we are hoping to be able to make the R library available to CRAN users for use
with Apache Spark or for reading and writing Parquet files over the next
quarter.&lt;/p&gt;

&lt;p&gt;Users of the &lt;code class=&quot;highlighter-rouge&quot;&gt;feather&lt;/code&gt; R library will see significant speed increases in many
cases when reading Feather files with the new Arrow R library.&lt;/p&gt;

&lt;h2 id=&quot;rust-notes&quot;&gt;Rust notes&lt;/h2&gt;

&lt;p&gt;Rust development had an active last 3 months; see the changelog for details.&lt;/p&gt;

&lt;p&gt;A native Rust implementation was just donated to the project, and the community
intends to provide a similar level of functionality for reading and writing
Parquet files using the Arrow in-memory columnar format as an intermediary.&lt;/p&gt;

&lt;h2 id=&quot;upcoming-roadmap-outlook-for-2019&quot;&gt;Upcoming Roadmap, Outlook for 2019&lt;/h2&gt;

&lt;p&gt;Apache Arrow has become a large, diverse open source project. It is now being
used in dozens of downstream open source and commercial projects. Work will be
proceeding in many areas in 2019:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Development of in-memory query execution engines (e.g. in C++, Rust)&lt;/li&gt;
  &lt;li&gt;Expanded support for reading and writing the Apache Parquet format, and other
common data formats like Apache Avro, CSV, JSON, and Apache ORC.&lt;/li&gt;
  &lt;li&gt;New Flight RPC system for fast messaging of Arrow datasets&lt;/li&gt;
  &lt;li&gt;Expanded support in existing programming languages&lt;/li&gt;
  &lt;li&gt;New programming language bindings or native implementations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It promises to be an exciting 2019. We look forward to having you involved in
the development community.&lt;/p&gt;</content><author><name>wesm</name></author></entry><entry><title type="html">Gandiva: A LLVM-based Analytical Expression Compiler for Apache Arrow</title><link href="/blog/2018/12/05/gandiva-donation/" rel="alternate" type="text/html" title="Gandiva: A LLVM-based Analytical Expression Compiler for Apache Arrow" /><published>2018-12-05T00:00:00-05:00</published><updated>2018-12-05T00:00:00-05:00</updated><id>/blog/2018/12/05/gandiva-donation</id><content type="html" xml:base="/blog/2018/12/05/gandiva-donation/">&lt;!--

--&gt;

&lt;p&gt;Today we’re happy to announce that the Gandiva Initiative for Apache Arrow, an
LLVM-based execution kernel, is now part of the Apache Arrow project. Gandiva
was kindly donated by &lt;a href=&quot;https://www.dremio.com/&quot;&gt;Dremio&lt;/a&gt;, where it was
originally developed and open-sourced. Gandiva extends Arrow’s capabilities to
provide high performance analytical execution and is composed of two main
components:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A runtime expression compiler leveraging LLVM&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A high performance execution environment&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gandiva works as follows: applications submit an expression tree to the
compiler, built in a language agnostic protobuf-based expression
representation. From there, Gandiva then compiles the expression tree to native
code for the current runtime environment and hardware. Once compiled, the
Gandiva execution kernel then consumes and produces Arrow columnar batches. The
generated code is highly optimized for parallel processing on modern CPUs. For
example, on AVX-128 processors Gandiva can process 8 pairs of 2 byte values in
a single vectorized operation, and on AVX-512 processors Gandiva can process 4x
as many values in a single operation. Gandiva is built from the ground up to
understand Arrow’s in-memory representation and optimize processing against it.&lt;/p&gt;

&lt;p&gt;While Gandiva is just starting within the Arrow community, it already supports
hundreds of &lt;a href=&quot;https://github.com/apache/arrow/blob/master/cpp/src/gandiva/function_registry.cc&quot;&gt;expressions&lt;/a&gt;, ranging from math functions to case
statements. Gandiva was built as a standalone C++ library built on top of the
core Apache Arrow codebase and was donated with C++ and Java APIs construction
and execution APIs for projection and filtering operations. The Arrow community
is already looking to expand Gandiva’s capabilities. This will include
incorporating more operations and supporting many new language bindings. As an
example, multiple community members are already actively building new language
bindings that allow use of Gandiva within Python and Ruby.&lt;/p&gt;

&lt;p&gt;While young within the Arrow community, Gandiva is already shipped and used in
production by many Dremio customers as part of Dremio’s execution
engine. Experiments have demonstrated &lt;a href=&quot;https://www.dremio.com/gandiva-performance-improvements-production-query/&quot;&gt;70x performance improvement&lt;/a&gt; on many
SQL queries. We expect to see similar performance gains for many other projects
that leverage Arrow.&lt;/p&gt;

&lt;p&gt;The Arrow community is working to ship the first formal Apache Arrow release
that includes Gandiva, and we hope this will be available within the next
couple months. This should make it much easier for the broader analytics and
data science development communities to leverage runtime code generation for
high-performance data processing in a variety of contexts and projects.&lt;/p&gt;

&lt;p&gt;We started the Arrow project a couple of years ago with the objective of
creating an industry-standard columnar in-memory data representation for
analytics. Within this short period of time, Apache Arrow has been adopted by
dozens of both open source and commercial software products. Some key examples
include technologies such as Apache Spark, Pandas, Nvidia RAPIDS, Dremio, and
InfluxDB. This success has driven Arrow to now be downloaded more than 1
million times per month. Over 200 developers have already contributed to Apache
Arrow. If you’re interested in contributing to Gandiva or any other part of the
Apache Arrow project, feel free to reach out on the mailing list and join us!&lt;/p&gt;

&lt;p&gt;For additional technical details on Gandiva, you can check out some of the
following resources:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.dremio.com/announcing-gandiva-initiative-for-apache-arrow/&quot;&gt;https://www.dremio.com/announcing-gandiva-initiative-for-apache-arrow/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.dremio.com/gandiva-performance-improvements-production-query/&quot;&gt;https://www.dremio.com/gandiva-performance-improvements-production-query/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.dremio.com/webinars/vectorized-query-processing-apache-arrow/&quot;&gt;https://www.dremio.com/webinars/vectorized-query-processing-apache-arrow/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.dremio.com/adding-a-user-define-function-to-gandiva/&quot;&gt;https://www.dremio.com/adding-a-user-define-function-to-gandiva/&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>jacques</name></author></entry><entry><title type="html">Apache Arrow 0.11.0 Release</title><link href="/blog/2018/10/09/0.11.0-release/" rel="alternate" type="text/html" title="Apache Arrow 0.11.0 Release" /><published>2018-10-09T00:00:00-04:00</published><updated>2018-10-09T00:00:00-04:00</updated><id>/blog/2018/10/09/0.11.0-release</id><content type="html" xml:base="/blog/2018/10/09/0.11.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 0.11.0 release. It is the
product of 2 months of development and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20in%20(Resolved%2C%20Closed)%20AND%20fixVersion%20%3D%200.11.0&quot;&gt;&lt;strong&gt;287 resolved
issues&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://arrow.apache.org/install&quot;&gt;Install Page&lt;/a&gt; to learn how to get the libraries for your
platform. The &lt;a href=&quot;https://arrow.apache.org/release/0.11.0.html&quot;&gt;complete changelog&lt;/a&gt; is also available.&lt;/p&gt;

&lt;p&gt;We discuss some highlights from the release and other project news in this
post.&lt;/p&gt;

&lt;h2 id=&quot;arrow-flight-rpc-and-messaging-framework&quot;&gt;Arrow Flight RPC and Messaging Framework&lt;/h2&gt;

&lt;p&gt;We are developing a new Arrow-native RPC framework, Arrow Flight, based on
&lt;a href=&quot;http://grpc.io&quot;&gt;gRPC&lt;/a&gt; for high performance Arrow-based messaging. Through low-level
extensions to gRPC’s internal memory management, we are able to avoid expensive
parsing when receiving datasets over the wire, unlocking unprecedented levels
of performance in moving datasets from one machine to another. We will be
writing more about Flight on the Arrow blog in the future.&lt;/p&gt;

&lt;p&gt;Prototype implementations are available in Java and C++, and we will be focused
in the coming months on hardening the Flight RPC framework for enterprise-grade
production use cases.&lt;/p&gt;

&lt;h2 id=&quot;parquet-and-arrow-c-communities-joining-forces&quot;&gt;Parquet and Arrow C++ communities joining forces&lt;/h2&gt;

&lt;p&gt;After discussion over the last year, the Apache Arrow and Apache Parquet C++
communities decide to merge the Parquet C++ codebase into the Arrow C++
codebase and work together in a “monorepo” structure. This should result in
better developer productivity in core Parquet work as well as in Arrow
integration.&lt;/p&gt;

&lt;p&gt;Before this codebase merge, we had a circular dependency between the Arrow and
Parquet codebases, since the Parquet C++ library is used in the Arrow Python
library.&lt;/p&gt;

&lt;h2 id=&quot;gandiva-llvm-expression-compiler-donation&quot;&gt;Gandiva LLVM Expression Compiler donation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://dremio.com&quot;&gt;Dremio Corporation&lt;/a&gt; has donated the &lt;a href=&quot;http://github.com/dremio/gandiva&quot;&gt;Gandiva&lt;/a&gt; LLVM expression compiler
to Apache Arrow. We will be working on cross-platform builds, packaging, and
language bindings (e.g. in Python) for Gandiva in the upcoming 0.12 release and
beyond. We will write more about Gandiva in the future.&lt;/p&gt;

&lt;h2 id=&quot;parquet-c-glib-bindings-donation&quot;&gt;Parquet C GLib Bindings Donation&lt;/h2&gt;

&lt;p&gt;PMC member &lt;a href=&quot;https://github.com/kou&quot;&gt;Kouhei Sutou&lt;/a&gt; has donated GLib bindings for the Parquet C++
libraries, which are designed to work together with the existing Arrow GLib
bindings.&lt;/p&gt;

&lt;h2 id=&quot;c-csv-reader-project&quot;&gt;C++ CSV Reader Project&lt;/h2&gt;

&lt;p&gt;We have begun developing a general purpose multithreaded CSV file parser in
C++. The purpose of this library is to parse and convert comma-separated text
files into Arrow columnar record batches as efficiently as possible. The
prototype version features Python bindings, and any language that can use the
C++ libraries (including C, R, and Ruby).&lt;/p&gt;

&lt;h2 id=&quot;new-matlab-bindings&quot;&gt;New MATLAB bindings&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://mathworks.com&quot;&gt;The MathWorks&lt;/a&gt; has contributed an initial MEX file binding to the Arrow
C++ libraries. Initially, it is possible to read Arrow-based Feather files in
MATLAB. We are looking forward to seeing more developments for MATLAB users.&lt;/p&gt;

&lt;h2 id=&quot;r-library-in-development&quot;&gt;R Library in Development&lt;/h2&gt;

&lt;p&gt;The community has begun implementing &lt;a href=&quot;https://github.com/apache/arrow/tree/master/r&quot;&gt;R language bindings and interoperability&lt;/a&gt;
with the Arrow C++ libraries. This will include support for zero-copy shared
memory IPC and other tools needed to improve R integration with Apache Spark
and more.&lt;/p&gt;

&lt;h2 id=&quot;support-for-cuda-based-gpus-in-python&quot;&gt;Support for CUDA-based GPUs in Python&lt;/h2&gt;

&lt;p&gt;This release includes Python bindings to the Arrow CUDA integration C++
library. This work is targeting interoperability with &lt;a href=&quot;https://github.com/numba/numba&quot;&gt;Numba&lt;/a&gt; and the &lt;a href=&quot;http://gpuopenanalytics.com/&quot;&gt;GPU
Open Analytics Initiative&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upcoming-roadmap&quot;&gt;Upcoming Roadmap&lt;/h2&gt;

&lt;p&gt;In the coming months, we will continue to make progress on many fronts, with
Gandiva packaging, expanded language support (especially in R), and improved
data access (e.g. CSV, Parquet files) in focus.&lt;/p&gt;</content><author><name>wesm</name></author></entry><entry><title type="html">Apache Arrow 0.10.0 Release</title><link href="/blog/2018/08/07/0.10.0-release/" rel="alternate" type="text/html" title="Apache Arrow 0.10.0 Release" /><published>2018-08-07T00:00:00-04:00</published><updated>2018-08-07T00:00:00-04:00</updated><id>/blog/2018/08/07/0.10.0-release</id><content type="html" xml:base="/blog/2018/08/07/0.10.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 0.10.0 release. It is the
product of over 4 months of development and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20in%20(Resolved%2C%20Closed)%20AND%20fixVersion%20%3D%200.10.0&quot;&gt;&lt;strong&gt;470 resolved
issues&lt;/strong&gt;&lt;/a&gt;. It is the largest release so far in the project’s history. 90
individuals contributed to this release.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://arrow.apache.org/install&quot;&gt;Install Page&lt;/a&gt; to learn how to get the libraries for your
platform. The &lt;a href=&quot;https://arrow.apache.org/release/0.10.0.html&quot;&gt;complete changelog&lt;/a&gt; is also available.&lt;/p&gt;

&lt;p&gt;We discuss some highlights from the release and other project news in this
post.&lt;/p&gt;

&lt;h2 id=&quot;offical-binary-packages-and-packaging-automation&quot;&gt;Offical Binary Packages and Packaging Automation&lt;/h2&gt;

&lt;p&gt;One of the largest projects in this release cycle was automating our build and
packaging tooling to be able to easily and reproducibly create a &lt;a href=&quot;https://www.apache.org/dyn/closer.cgi/arrow/arrow-0.10.0/binaries&quot;&gt;comprehensive
set of binary artifacts&lt;/a&gt; which have been approved and released by the Arrow
PMC. We developed a tool called &lt;strong&gt;Crossbow&lt;/strong&gt; which uses Appveyor and Travis CI
to build each of the different supported packages on all 3 platforms (Linux,
macOS, and Windows). As a result of our efforts, we should be able to make more
frequent Arrow releases. This work was led by Phillip Cloud, Kouhei Sutou, and
Krisztián Szűcs. Bravo!&lt;/p&gt;

&lt;h2 id=&quot;new-programming-languages-go-ruby-rust&quot;&gt;New Programming Languages: Go, Ruby, Rust&lt;/h2&gt;

&lt;p&gt;This release also adds 3 new programming languages to the project: Go, Ruby,
and Rust. Together with C, C++, Java, JavaScript, and Python, &lt;strong&gt;we now have
some level of support for 8 programming languages&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upcoming-roadmap&quot;&gt;Upcoming Roadmap&lt;/h2&gt;

&lt;p&gt;In the coming months, we will be working to move Apache Arrow closer to a 1.0.0
release. We will continue to grow new features, improve performance and
stability, and expand support for currently supported and new programming
languages.&lt;/p&gt;</content><author><name>wesm</name></author></entry><entry><title type="html">Faster, scalable memory allocations in Apache Arrow with jemalloc</title><link href="/blog/2018/07/20/jemalloc/" rel="alternate" type="text/html" title="Faster, scalable memory allocations in Apache Arrow with jemalloc" /><published>2018-07-20T07:00:00-04:00</published><updated>2018-07-20T07:00:00-04:00</updated><id>/blog/2018/07/20/jemalloc</id><content type="html" xml:base="/blog/2018/07/20/jemalloc/">&lt;!--

--&gt;

&lt;p&gt;With the release of the 0.9 version of Apache Arrow, we have switched our
default allocator for array buffers from the system allocator to jemalloc on
OSX and Linux. This applies to the C++/GLib/Python implementations of Arrow.
In most cases changing the default allocator is normally done to avoid problems
that occur with many small, frequent (de)allocations. In contrast, in Arrow we
normally deal with large in-memory datasets. While jemalloc provides good
strategies for &lt;a href=&quot;https://zapier.com/engineering/celery-python-jemalloc/&quot;&gt;avoiding RAM fragmentation for allocations that are lower than
a memory page (4kb)&lt;/a&gt;, it also provides functionality that improves
performance on allocations that span several memory pages.&lt;/p&gt;

&lt;p&gt;Outside of Apache Arrow, &lt;a href=&quot;https://www.facebook.com/notes/facebook-engineering/scalable-memory-allocation-using-jemalloc/480222803919/&quot;&gt;jemalloc powers the infrastructure of Facebook&lt;/a&gt;
(this is also where most of its development happens). It is also used as the
&lt;a href=&quot;https://github.com/rust-lang/rust/pull/6895&quot;&gt;default allocator in Rust&lt;/a&gt; as well as it helps &lt;a href=&quot;http://download.redis.io/redis-stable/README.md&quot;&gt;Redis reduce the memory
fragmentation on Linux&lt;/a&gt; (“Allocator”).&lt;/p&gt;

&lt;p&gt;One allocation specialty that we require in Arrow is that memory should be
64byte aligned. This is so that we can get the most performance out of SIMD
instruction sets like AVX. While the most modern SIMD instructions also work on
unaligned memory, their performance is much better on aligned memory. To get the
best performance for our analytical applications, we want all memory to be
allocated such that SIMD performance is maximized.&lt;/p&gt;

&lt;p&gt;For aligned allocations, the POSIX APIs only provide the
&lt;code class=&quot;highlighter-rouge&quot;&gt;aligned_alloc(void** ptr, size_t alignment, size_t size)&lt;/code&gt; function to
allocate aligned memory. There is also 
&lt;code class=&quot;highlighter-rouge&quot;&gt;posix_memalign(void **ptr, size_t alignment, size_t size)&lt;/code&gt; to modify an
allocation to the preferred alignment. But neither of them cater for expansions
of the allocation. While the &lt;code class=&quot;highlighter-rouge&quot;&gt;realloc&lt;/code&gt; function can often expand allocations
without moving them physically, it does not ensure that in the case the
allocation is moved that the alignment is kept.&lt;/p&gt;

&lt;p&gt;In the case when Arrow was built without jemalloc being enabled, this resulted
in copying the data on each new expansion of an allocation. To reduce the number
of memory copies, we use jemalloc’s &lt;code class=&quot;highlighter-rouge&quot;&gt;*allocx()&lt;/code&gt;-APIs to create, modify and free
aligned allocations. One of the typical tasks where this gives us a major
speedup is on the incremental construction of an Arrow table that consists of
several columns. We often don’t know the size of the table in advance and need
to expand our allocations as the data is loaded.&lt;/p&gt;

&lt;p&gt;To incrementally build a vector using memory expansion of a factor of 2, we
would use the following C-code with the standard POSIX APIs:&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aligned_alloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aligned_alloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;memcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;free&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With jemalloc’s special APIs, we are able to omit the explicit call to &lt;code class=&quot;highlighter-rouge&quot;&gt;memcpy&lt;/code&gt;.
In the case where a memory expansion cannot be done in-place, it is still called
by the allocator but not needed on all occasions. This simplifies our user code
to:&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mallocx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MALLOCX_ALIGN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rallocx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MALLOCX_ALIGN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dallocx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MALLOCX_ALIGN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To see the real world benefits of using jemalloc, we look at the benchmarks in
Arrow C++. There we have modeled a typical use case of incrementally building up
an array of primitive values. For the build-up of the array, we don’t know the
number of elements in the final array so we need to continuously expand the
memory region in which the data is stored. The code for this benchmark is part
of the &lt;code class=&quot;highlighter-rouge&quot;&gt;builder-benchmark&lt;/code&gt; in the Arrow C++ sources as
&lt;code class=&quot;highlighter-rouge&quot;&gt;BuildPrimitiveArrayNoNulls&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Runtimes without &lt;code class=&quot;highlighter-rouge&quot;&gt;jemalloc&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BM_BuildPrimitiveArrayNoNulls/repeats:3                 636726 us   804.114MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 621345 us   824.019MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 625008 us    819.19MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_mean            627693 us   815.774MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_median          625008 us    819.19MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev            8034 us   10.3829MB/s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Runtimes with &lt;code class=&quot;highlighter-rouge&quot;&gt;jemalloc&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;BM_BuildPrimitiveArrayNoNulls/repeats:3                 630881 us   811.563MB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 352891 us   1.41687GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3                 351039 us   1.42434GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_mean            444937 us   1.21125GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_median          352891 us   1.41687GB/s
BM_BuildPrimitiveArrayNoNulls/repeats:3_stddev          161035 us   371.335MB/s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The benchmark was run three times for each configuration to see the performance
differences. The first run in each configuration yielded the same performance but
in all subsequent runs, the version using jemalloc was about twice as fast. In
these cases, the memory region that was used for constructing the array could be
expanded in place without moving the data around. This was possible as there
were memory pages assigned to the process that were unused but not reclaimed by
the operating system. Without &lt;code class=&quot;highlighter-rouge&quot;&gt;jemalloc&lt;/code&gt;, we cannot make use of them simply by
the fact that the default allocator has no API that provides aligned
reallocation.&lt;/p&gt;</content><author><name>uwe</name></author></entry><entry><title type="html">Apache Arrow 0.9.0 Release</title><link href="/blog/2018/03/22/0.9.0-release/" rel="alternate" type="text/html" title="Apache Arrow 0.9.0 Release" /><published>2018-03-22T00:00:00-04:00</published><updated>2018-03-22T00:00:00-04:00</updated><id>/blog/2018/03/22/0.9.0-release</id><content type="html" xml:base="/blog/2018/03/22/0.9.0-release/">&lt;!--

--&gt;

&lt;p&gt;The Apache Arrow team is pleased to announce the 0.9.0 release. It is the
product of over 3 months of development and includes &lt;a href=&quot;https://issues.apache.org/jira/issues/?jql=project%20%3D%20ARROW%20AND%20status%20in%20(Resolved%2C%20Closed)%20AND%20fixVersion%20%3D%200.9.0&quot;&gt;&lt;strong&gt;260 resolved
JIRAs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While we made some of backwards-incompatible columnar binary format changes in
last December’s 0.8.0 release, the 0.9.0 release is backwards-compatible with
0.8.0. We will be working toward a 1.0.0 release this year, which will mark
longer-term binary stability for the Arrow columnar format and metadata.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&quot;https://arrow.apache.org/install&quot;&gt;Install Page&lt;/a&gt; to learn how to get the libraries for your
platform. The &lt;a href=&quot;https://arrow.apache.org/release/0.8.0.html&quot;&gt;complete changelog&lt;/a&gt; is also available.&lt;/p&gt;

&lt;p&gt;We discuss some highlights from the release and other project news in this
post. This release has been overall focused more on bug fixes, compatibility,
and stability compared with previous releases which have pushed more on new and
expanded features.&lt;/p&gt;

&lt;h2 id=&quot;new-arrow-committers-and-pmc-members&quot;&gt;New Arrow committers and PMC members&lt;/h2&gt;

&lt;p&gt;Since the last release, we have added 2 new Arrow committers: &lt;a href=&quot;https://github.com/theneuralbit&quot;&gt;Brian
Hulette&lt;/a&gt; and &lt;a href=&quot;https://github.com/robertnishihara&quot;&gt;Robert Nishihara&lt;/a&gt;. Additionally, &lt;a href=&quot;https://github.com/cpcloud&quot;&gt;Phillip Cloud&lt;/a&gt; and
&lt;a href=&quot;https://github.com/pcmoritz&quot;&gt;Philipp Moritz&lt;/a&gt; have been promoted from committer to PMC
member. Congratulations and thank you for your contributions!&lt;/p&gt;

&lt;h2 id=&quot;plasma-object-store-improvements&quot;&gt;Plasma Object Store Improvements&lt;/h2&gt;

&lt;p&gt;The Plasma Object Store now supports managing interprocess shared memory on
CUDA-enabled GPUs. We are excited to see more GPU-related functionality develop
in Apache Arrow, as this has become a key computing environment for scalable
machine learning.&lt;/p&gt;

&lt;h2 id=&quot;python-improvements&quot;&gt;Python Improvements&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/pitrou&quot;&gt;Antoine Pitrou&lt;/a&gt; has joined the Python development efforts and helped
significantly this release with interoperability with built-in CPython data
structures and NumPy structured data types.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;New experimental support for reading Apache ORC files&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.array&lt;/code&gt; now accepts lists of tuples or Python dicts for creating
Arrow struct type arrays.&lt;/li&gt;
  &lt;li&gt;NumPy structured dtypes (which are row/record-oriented) can be directly
converted to Arrow struct (column-oriented) arrays&lt;/li&gt;
  &lt;li&gt;Python 3.6 &lt;code class=&quot;highlighter-rouge&quot;&gt;pathlib&lt;/code&gt; objects for file paths are now accepted in many file
APIs, including for Parquet files&lt;/li&gt;
  &lt;li&gt;Arrow integer arrays with nulls can now be converted to NumPy object arrays
with &lt;code class=&quot;highlighter-rouge&quot;&gt;None&lt;/code&gt; values&lt;/li&gt;
  &lt;li&gt;New &lt;code class=&quot;highlighter-rouge&quot;&gt;pyarrow.foreign_buffer&lt;/code&gt; API for interacting with memory blocks located
at particular memory addresses&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;java-improvements&quot;&gt;Java Improvements&lt;/h2&gt;

&lt;p&gt;Java now fully supports the &lt;code class=&quot;highlighter-rouge&quot;&gt;FixedSizeBinary&lt;/code&gt; data type.&lt;/p&gt;

&lt;h2 id=&quot;javascript-improvements&quot;&gt;JavaScript Improvements&lt;/h2&gt;

&lt;p&gt;The JavaScript library has been significantly refactored and expanded. We are
making separate Apache releases (most recently &lt;code class=&quot;highlighter-rouge&quot;&gt;JS-0.3.1&lt;/code&gt;) for JavaScript,
which are being &lt;a href=&quot;https://www.npmjs.com/package/apache-arrow&quot;&gt;published to NPM&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;upcoming-roadmap&quot;&gt;Upcoming Roadmap&lt;/h2&gt;

&lt;p&gt;In the coming months, we will be working to move Apache Arrow closer to a 1.0.0
release. We will also be discussing plans to develop native Arrow-based
computational libraries within the project.&lt;/p&gt;</content><author><name>wesm</name></author></entry></feed>