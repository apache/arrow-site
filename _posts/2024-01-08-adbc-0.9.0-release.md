---
layout: post
title: "Apache Arrow ADBC 0.9.0 (Libraries) Release"
date: "2024-01-08 00:00:00"
author: pmc
categories: [release]
---
<!--
{% comment %}
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to you under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
{% endcomment %}
-->

The Apache Arrow team is pleased to announce the 0.9.0 release of
the Apache Arrow ADBC libraries. This covers includes [**34
resolved issues**][1] from [**16 distinct contributors**][2].

This is a release of the **libraries**, which are at version
0.9.0.  The **API specification** is versioned separately and is
at version 1.1.0.

The release notes below are not exhaustive and only expose selected
highlights of the release. Many other bugfixes and improvements have
been made: we refer you to the [complete changelog][3].

## Release Highlights

The C#/.NET implementation is gearing up for a proper release and has had
various bugfixes in the core libraries, the drivers, and the ADO.NET wrapper.

The Go implementation now supports executing more methods (like
`ConnectionCommit`) when importing a native C/C++ driver.

The PostgreSQL driver can now write decimal values and dictionary-encoded
string/bytestring.  Also, `AdbcConnectionGetTableSchema` was fixed to handle
the catalog and schema parameters correctly, and the driver now tries to
provide a row count for non-select queries.

The Python bindings now accept a PyArrow Dataset as a data source for bulk
ingestion.  The new [PyCapsule interface][pycapsule] is supported.  It is
possible to build the Python packages via CMake, which simplifies handling the
mixed-C++-and-Python builds.

The R bindings reference-count objects to try to detect improper usage and
avoid crashes.

The Snowflake driver properly handles escaping and case sensitivity in various
metadata methods.  It also now supports `StatementExecuteSchema`.

The Javadoc API reference is now included in the documentation.

[pycapsule]: https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html

## Contributors

```
$ git shortlog --perl-regexp --author='^((?!dependabot\[bot\]).*)$' -sn apache-arrow-adbc-0.8.0..apache-arrow-adbc-0.9.0
    24	David Li
    10	Curt Hagenlocher
    10	Dewey Dunnington
     7	davidhcoe
     4	William Ayd
     3	Ryan Syed
     3	vleslief-ms
     2	Daniel Espinosa
     2	Joel Lubinitsky
     2	Sutou Kouhei
     1	AnithaPanduranganMS
     1	Joris Van den Bossche
     1	Matt Topol
     1	Ruoxuan Wang
     1	William
     1	rtadepalli
```

## Roadmap

The next release may increase the minimum required C++ revision to C++17,
which will line up with the mainline Arrow project
([GH-1431](https://github.com/apache/arrow-adbc/issues/1431)).

## Getting Involved

We welcome questions and contributions from all interested.  Issues
can be filed on [GitHub][4], and questions can be directed to GitHub
or the [Arrow mailing lists][5].

[1]: https://github.com/apache/arrow-adbc/milestone/13
[2]: #contributors
[3]: https://github.com/apache/arrow-adbc/blob/apache-arrow-adbc-0.9.0/CHANGELOG.md
[4]: https://github.com/apache/arrow-adbc/issues
[5]: {% link community.md %}
